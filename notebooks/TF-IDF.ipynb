{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get phrase counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickles/counter_Z.pickle', 'rb') as inputfile:\n",
    "    a = pickle.load(inputfile)\n",
    "with open('../pickles/counter_Z2.pickle', 'rb') as inputfile:\n",
    "    b = pickle.load(inputfile)\n",
    "with open('../pickles/counter_Z3.pickle', 'rb') as inputfile:\n",
    "    c = pickle.load(inputfile)\n",
    "with open('../pickles/counter_Z4.pickle', 'rb') as inputfile:\n",
    "    d = pickle.load(inputfile)\n",
    "with open('../pickles/counter_Z5.pickle', 'rb') as inputfile:\n",
    "    e = pickle.load(inputfile)\n",
    "with open('../pickles/counter_Z6.pickle', 'rb') as inputfile:\n",
    "    f = pickle.load(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_counter = a + b + c + d + e + f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top300k = phrase_counter.most_common(300000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = scipy.sparse.load_npz('../data/count_vect.npz')\n",
    "feat_vect = np.load('../data/vect_feat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = {'word': feat_vect, 'count':count_vect.sum(axis = 0).tolist()[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = pd.DataFrame(count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = count_df.set_index('word', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>2463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>60512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000000</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count\n",
       "word          \n",
       "00        2463\n",
       "000      60512\n",
       "0000        26\n",
       "00000        4\n",
       "0000000      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = count_df.to_dict()['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(top300k)\n",
    "df300k = pd.DataFrame(data=arr, columns=['phrases', 'counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df = df300k.phrases.str.split(' ', expand=True)\n",
    "split_df['phrases'] = df300k.phrases\n",
    "split_df['phrase_count'] = df300k.counts.astype(int)\n",
    "split_df.rename(columns={0:'w_one', 1:'w_two'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_one</th>\n",
       "      <th>w_two</th>\n",
       "      <th>phrases</th>\n",
       "      <th>phrase_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last</td>\n",
       "      <td>year</td>\n",
       "      <td>last year</td>\n",
       "      <td>19906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>last</td>\n",
       "      <td>week</td>\n",
       "      <td>last week</td>\n",
       "      <td>15305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>years</td>\n",
       "      <td>ago</td>\n",
       "      <td>years ago</td>\n",
       "      <td>14025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first</td>\n",
       "      <td>time</td>\n",
       "      <td>first time</td>\n",
       "      <td>10717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>social</td>\n",
       "      <td>media</td>\n",
       "      <td>social media</td>\n",
       "      <td>10634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    w_one  w_two       phrases  phrase_count\n",
       "0    last   year     last year         19906\n",
       "1    last   week     last week         15305\n",
       "2   years    ago     years ago         14025\n",
       "3   first   time    first time         10717\n",
       "4  social  media  social media         10634"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglish(s):\n",
    "    return s.isascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_english = split_df[~split_df.phrases.apply(lambda x: isEnglish(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df = split_df[split_df.phrases.apply(lambda x: isEnglish(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df = split_df[split_df.w_one.apply(lambda x: len(x)) > 2]\n",
    "split_df = split_df[split_df.w_two.apply(lambda x: len(x)) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df['freq_one'] = split_df.w_one.apply(lambda x: freq_dict[x])\n",
    "split_df['freq_two'] = split_df.w_two.apply(lambda x: freq_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df['mean_freq_ratio'] = split_df.phrase_count / ((split_df.freq_one + split_df.freq_two)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "infinity = split_df[split_df.mean_freq_ratio > 10].index\n",
    "split_df.drop(infinity, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10k = split_df.mean_freq_ratio.nlargest(10000).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([288873,  65357,  72692,  72641, 133769, 257426,  13521, 106351,\n",
       "            282562,  43604,\n",
       "            ...\n",
       "            274039, 288951,  22975,  67386,   6786, 116206, 152514,   4519,\n",
       "             38900,  86279],\n",
       "           dtype='int64', length=10000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = split_df.loc[top10k,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_one</th>\n",
       "      <th>w_two</th>\n",
       "      <th>phrases</th>\n",
       "      <th>phrase_count</th>\n",
       "      <th>freq_one</th>\n",
       "      <th>freq_two</th>\n",
       "      <th>mean_freq_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288873</th>\n",
       "      <td>hemolytic</td>\n",
       "      <td>uremic</td>\n",
       "      <td>hemolytic uremic</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65357</th>\n",
       "      <td>hoi</td>\n",
       "      <td>polloi</td>\n",
       "      <td>hoi polloi</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>0.893617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72692</th>\n",
       "      <td>vas</td>\n",
       "      <td>deferens</td>\n",
       "      <td>vas deferens</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72641</th>\n",
       "      <td>situs</td>\n",
       "      <td>inversus</td>\n",
       "      <td>situs inversus</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>0.816327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133769</th>\n",
       "      <td>myocardial</td>\n",
       "      <td>infarction</td>\n",
       "      <td>myocardial infarction</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             w_one       w_two                phrases  phrase_count  freq_one  \\\n",
       "288873   hemolytic      uremic       hemolytic uremic             5         5   \n",
       "65357          hoi      polloi             hoi polloi            21        24   \n",
       "72692          vas    deferens           vas deferens            20        28   \n",
       "72641        situs    inversus         situs inversus            20        25   \n",
       "133769  myocardial  infarction  myocardial infarction            11        13   \n",
       "\n",
       "        freq_two  mean_freq_ratio  \n",
       "288873         5         1.000000  \n",
       "65357         23         0.893617  \n",
       "72692         20         0.833333  \n",
       "72641         24         0.816327  \n",
       "133769        14         0.814815  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_one</th>\n",
       "      <th>w_two</th>\n",
       "      <th>phrases</th>\n",
       "      <th>phrase_count</th>\n",
       "      <th>freq_one</th>\n",
       "      <th>freq_two</th>\n",
       "      <th>mean_freq_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>pepper</td>\n",
       "      <td>spray</td>\n",
       "      <td>pepper spray</td>\n",
       "      <td>301</td>\n",
       "      <td>1029</td>\n",
       "      <td>982</td>\n",
       "      <td>0.299354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15222</th>\n",
       "      <td>softwood</td>\n",
       "      <td>lumber</td>\n",
       "      <td>softwood lumber</td>\n",
       "      <td>75</td>\n",
       "      <td>99</td>\n",
       "      <td>404</td>\n",
       "      <td>0.298211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>fetal</td>\n",
       "      <td>tissue</td>\n",
       "      <td>fetal tissue</td>\n",
       "      <td>303</td>\n",
       "      <td>823</td>\n",
       "      <td>1247</td>\n",
       "      <td>0.292754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>receive</td>\n",
       "      <td>updates</td>\n",
       "      <td>receive updates</td>\n",
       "      <td>2113</td>\n",
       "      <td>9569</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.292153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5055</th>\n",
       "      <td>densely</td>\n",
       "      <td>populated</td>\n",
       "      <td>densely populated</td>\n",
       "      <td>180</td>\n",
       "      <td>318</td>\n",
       "      <td>918</td>\n",
       "      <td>0.291262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176588</th>\n",
       "      <td>bete</td>\n",
       "      <td>noire</td>\n",
       "      <td>bete noire</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>51</td>\n",
       "      <td>0.290323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>secured</td>\n",
       "      <td>unconditional</td>\n",
       "      <td>secured unconditional</td>\n",
       "      <td>384</td>\n",
       "      <td>2037</td>\n",
       "      <td>615</td>\n",
       "      <td>0.289593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21056</th>\n",
       "      <td>haute</td>\n",
       "      <td>couture</td>\n",
       "      <td>haute couture</td>\n",
       "      <td>57</td>\n",
       "      <td>162</td>\n",
       "      <td>232</td>\n",
       "      <td>0.289340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51308</th>\n",
       "      <td>prefrontal</td>\n",
       "      <td>cortex</td>\n",
       "      <td>prefrontal cortex</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>157</td>\n",
       "      <td>0.287234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97263</th>\n",
       "      <td>fidget</td>\n",
       "      <td>spinners</td>\n",
       "      <td>fidget spinners</td>\n",
       "      <td>15</td>\n",
       "      <td>44</td>\n",
       "      <td>61</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195212</th>\n",
       "      <td>whirling</td>\n",
       "      <td>dervish</td>\n",
       "      <td>whirling dervish</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247290</th>\n",
       "      <td>boa</td>\n",
       "      <td>constrictor</td>\n",
       "      <td>boa constrictor</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>blocking</td>\n",
       "      <td>ads</td>\n",
       "      <td>blocking ads</td>\n",
       "      <td>1672</td>\n",
       "      <td>3585</td>\n",
       "      <td>8139</td>\n",
       "      <td>0.285227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3868</th>\n",
       "      <td>genetically</td>\n",
       "      <td>modified</td>\n",
       "      <td>genetically modified</td>\n",
       "      <td>220</td>\n",
       "      <td>687</td>\n",
       "      <td>863</td>\n",
       "      <td>0.283871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>status</td>\n",
       "      <td>quo</td>\n",
       "      <td>status quo</td>\n",
       "      <td>1697</td>\n",
       "      <td>9788</td>\n",
       "      <td>2213</td>\n",
       "      <td>0.282810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141229</th>\n",
       "      <td>tater</td>\n",
       "      <td>tots</td>\n",
       "      <td>tater tots</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "      <td>0.278481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>unaccompanied</td>\n",
       "      <td>minors</td>\n",
       "      <td>unaccompanied minors</td>\n",
       "      <td>233</td>\n",
       "      <td>660</td>\n",
       "      <td>1037</td>\n",
       "      <td>0.274602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17125</th>\n",
       "      <td>non</td>\n",
       "      <td>grata</td>\n",
       "      <td>non grata</td>\n",
       "      <td>68</td>\n",
       "      <td>413</td>\n",
       "      <td>83</td>\n",
       "      <td>0.274194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187709</th>\n",
       "      <td>venous</td>\n",
       "      <td>thrombosis</td>\n",
       "      <td>venous thrombosis</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>34</td>\n",
       "      <td>0.271186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213884</th>\n",
       "      <td>rabble</td>\n",
       "      <td>rousers</td>\n",
       "      <td>rabble rousers</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>0.269231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4725</th>\n",
       "      <td>peanut</td>\n",
       "      <td>butter</td>\n",
       "      <td>peanut butter</td>\n",
       "      <td>190</td>\n",
       "      <td>496</td>\n",
       "      <td>918</td>\n",
       "      <td>0.268741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58050</th>\n",
       "      <td>amino</td>\n",
       "      <td>acids</td>\n",
       "      <td>amino acids</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>123</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>sexual</td>\n",
       "      <td>assault</td>\n",
       "      <td>sexual assault</td>\n",
       "      <td>3643</td>\n",
       "      <td>16271</td>\n",
       "      <td>11159</td>\n",
       "      <td>0.265622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124494</th>\n",
       "      <td>summa</td>\n",
       "      <td>cum</td>\n",
       "      <td>summa cum</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>62</td>\n",
       "      <td>0.263736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>card</td>\n",
       "      <td>processor</td>\n",
       "      <td>card processor</td>\n",
       "      <td>939</td>\n",
       "      <td>6026</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.260616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>background</td>\n",
       "      <td>checks</td>\n",
       "      <td>background checks</td>\n",
       "      <td>1311</td>\n",
       "      <td>6429</td>\n",
       "      <td>3651</td>\n",
       "      <td>0.260119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>battleground</td>\n",
       "      <td>prediction</td>\n",
       "      <td>battleground prediction</td>\n",
       "      <td>411</td>\n",
       "      <td>1868</td>\n",
       "      <td>1298</td>\n",
       "      <td>0.259634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21065</th>\n",
       "      <td>scantily</td>\n",
       "      <td>clad</td>\n",
       "      <td>scantily clad</td>\n",
       "      <td>57</td>\n",
       "      <td>68</td>\n",
       "      <td>374</td>\n",
       "      <td>0.257919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>display</td>\n",
       "      <td>ads</td>\n",
       "      <td>display ads</td>\n",
       "      <td>1718</td>\n",
       "      <td>5254</td>\n",
       "      <td>8139</td>\n",
       "      <td>0.256552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43847</th>\n",
       "      <td>conscientious</td>\n",
       "      <td>objector</td>\n",
       "      <td>conscientious objector</td>\n",
       "      <td>30</td>\n",
       "      <td>192</td>\n",
       "      <td>43</td>\n",
       "      <td>0.255319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>lame</td>\n",
       "      <td>duck</td>\n",
       "      <td>lame duck</td>\n",
       "      <td>170</td>\n",
       "      <td>417</td>\n",
       "      <td>1070</td>\n",
       "      <td>0.228648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88534</th>\n",
       "      <td>homeopathic</td>\n",
       "      <td>teething</td>\n",
       "      <td>homeopathic teething</td>\n",
       "      <td>16</td>\n",
       "      <td>65</td>\n",
       "      <td>76</td>\n",
       "      <td>0.226950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141876</th>\n",
       "      <td>inductive</td>\n",
       "      <td>coupling</td>\n",
       "      <td>inductive coupling</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>66</td>\n",
       "      <td>0.226804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61936</th>\n",
       "      <td>irritable</td>\n",
       "      <td>bowel</td>\n",
       "      <td>irritable bowel</td>\n",
       "      <td>23</td>\n",
       "      <td>87</td>\n",
       "      <td>118</td>\n",
       "      <td>0.224390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>conventional</td>\n",
       "      <td>wisdom</td>\n",
       "      <td>conventional wisdom</td>\n",
       "      <td>548</td>\n",
       "      <td>2818</td>\n",
       "      <td>2071</td>\n",
       "      <td>0.224177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>inner</td>\n",
       "      <td>circle</td>\n",
       "      <td>inner circle</td>\n",
       "      <td>612</td>\n",
       "      <td>2521</td>\n",
       "      <td>2982</td>\n",
       "      <td>0.222424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>quid</td>\n",
       "      <td>pro</td>\n",
       "      <td>quid pro</td>\n",
       "      <td>312</td>\n",
       "      <td>379</td>\n",
       "      <td>2441</td>\n",
       "      <td>0.221277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74251</th>\n",
       "      <td>rotator</td>\n",
       "      <td>cuff</td>\n",
       "      <td>rotator cuff</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>151</td>\n",
       "      <td>0.219653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7763</th>\n",
       "      <td>involuntary</td>\n",
       "      <td>manslaughter</td>\n",
       "      <td>involuntary manslaughter</td>\n",
       "      <td>129</td>\n",
       "      <td>389</td>\n",
       "      <td>786</td>\n",
       "      <td>0.219574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6788</th>\n",
       "      <td>genetically</td>\n",
       "      <td>engineered</td>\n",
       "      <td>genetically engineered</td>\n",
       "      <td>144</td>\n",
       "      <td>687</td>\n",
       "      <td>625</td>\n",
       "      <td>0.219512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24089</th>\n",
       "      <td>grossly</td>\n",
       "      <td>generalistic</td>\n",
       "      <td>grossly generalistic</td>\n",
       "      <td>51</td>\n",
       "      <td>410</td>\n",
       "      <td>58</td>\n",
       "      <td>0.217949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>chemical</td>\n",
       "      <td>weapons</td>\n",
       "      <td>chemical weapons</td>\n",
       "      <td>1892</td>\n",
       "      <td>5070</td>\n",
       "      <td>12434</td>\n",
       "      <td>0.216179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268695</th>\n",
       "      <td>graphing</td>\n",
       "      <td>calculators</td>\n",
       "      <td>graphing calculators</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107810</th>\n",
       "      <td>untitled</td>\n",
       "      <td>unmastered</td>\n",
       "      <td>untitled unmastered</td>\n",
       "      <td>14</td>\n",
       "      <td>112</td>\n",
       "      <td>19</td>\n",
       "      <td>0.213740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>voter</td>\n",
       "      <td>fraud</td>\n",
       "      <td>voter fraud</td>\n",
       "      <td>1487</td>\n",
       "      <td>7798</td>\n",
       "      <td>6246</td>\n",
       "      <td>0.211763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16292</th>\n",
       "      <td>wreaking</td>\n",
       "      <td>havoc</td>\n",
       "      <td>wreaking havoc</td>\n",
       "      <td>71</td>\n",
       "      <td>99</td>\n",
       "      <td>572</td>\n",
       "      <td>0.211624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>credit</td>\n",
       "      <td>card</td>\n",
       "      <td>credit card</td>\n",
       "      <td>1606</td>\n",
       "      <td>9157</td>\n",
       "      <td>6026</td>\n",
       "      <td>0.211552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15205</th>\n",
       "      <td>bumper</td>\n",
       "      <td>stickers</td>\n",
       "      <td>bumper stickers</td>\n",
       "      <td>75</td>\n",
       "      <td>348</td>\n",
       "      <td>365</td>\n",
       "      <td>0.210379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>hedge</td>\n",
       "      <td>fund</td>\n",
       "      <td>hedge fund</td>\n",
       "      <td>1373</td>\n",
       "      <td>2612</td>\n",
       "      <td>10447</td>\n",
       "      <td>0.210276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>maple</td>\n",
       "      <td>syrup</td>\n",
       "      <td>maple syrup</td>\n",
       "      <td>56</td>\n",
       "      <td>244</td>\n",
       "      <td>289</td>\n",
       "      <td>0.210131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>sparsely</td>\n",
       "      <td>populated</td>\n",
       "      <td>sparsely populated</td>\n",
       "      <td>117</td>\n",
       "      <td>198</td>\n",
       "      <td>918</td>\n",
       "      <td>0.209677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5231</th>\n",
       "      <td>bully</td>\n",
       "      <td>pulpit</td>\n",
       "      <td>bully pulpit</td>\n",
       "      <td>175</td>\n",
       "      <td>1258</td>\n",
       "      <td>415</td>\n",
       "      <td>0.209205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14082</th>\n",
       "      <td>bumper</td>\n",
       "      <td>sticker</td>\n",
       "      <td>bumper sticker</td>\n",
       "      <td>80</td>\n",
       "      <td>348</td>\n",
       "      <td>419</td>\n",
       "      <td>0.208605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>soap</td>\n",
       "      <td>opera</td>\n",
       "      <td>soap opera</td>\n",
       "      <td>189</td>\n",
       "      <td>706</td>\n",
       "      <td>1114</td>\n",
       "      <td>0.207692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414</th>\n",
       "      <td>downward</td>\n",
       "      <td>spiral</td>\n",
       "      <td>downward spiral</td>\n",
       "      <td>150</td>\n",
       "      <td>706</td>\n",
       "      <td>744</td>\n",
       "      <td>0.206897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>expanding</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>expanding stimulus</td>\n",
       "      <td>547</td>\n",
       "      <td>3668</td>\n",
       "      <td>1623</td>\n",
       "      <td>0.206766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>mental</td>\n",
       "      <td>illness</td>\n",
       "      <td>mental illness</td>\n",
       "      <td>950</td>\n",
       "      <td>6420</td>\n",
       "      <td>2879</td>\n",
       "      <td>0.204323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242378</th>\n",
       "      <td>aortic</td>\n",
       "      <td>aneurysm</td>\n",
       "      <td>aortic aneurysm</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>0.203390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225068</th>\n",
       "      <td>photon</td>\n",
       "      <td>thrusters</td>\n",
       "      <td>photon thrusters</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>46</td>\n",
       "      <td>0.202899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140141</th>\n",
       "      <td>noblesse</td>\n",
       "      <td>oblige</td>\n",
       "      <td>noblesse oblige</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>94</td>\n",
       "      <td>0.201835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                w_one          w_two                   phrases  phrase_count  \\\n",
       "2565           pepper          spray              pepper spray           301   \n",
       "15222        softwood         lumber           softwood lumber            75   \n",
       "2555            fetal         tissue              fetal tissue           303   \n",
       "105           receive        updates           receive updates          2113   \n",
       "5055          densely      populated         densely populated           180   \n",
       "176588           bete          noire                bete noire             9   \n",
       "1843          secured  unconditional     secured unconditional           384   \n",
       "21056           haute        couture             haute couture            57   \n",
       "51308      prefrontal         cortex         prefrontal cortex            27   \n",
       "97263          fidget       spinners           fidget spinners            15   \n",
       "195212       whirling        dervish          whirling dervish             8   \n",
       "247290            boa    constrictor           boa constrictor             6   \n",
       "182          blocking            ads              blocking ads          1672   \n",
       "3868      genetically       modified      genetically modified           220   \n",
       "174            status            quo                status quo          1697   \n",
       "141229          tater           tots                tater tots            11   \n",
       "3633    unaccompanied         minors      unaccompanied minors           233   \n",
       "17125             non          grata                 non grata            68   \n",
       "187709         venous     thrombosis         venous thrombosis             8   \n",
       "213884         rabble        rousers            rabble rousers             7   \n",
       "4725           peanut         butter             peanut butter           190   \n",
       "58050           amino          acids               amino acids            24   \n",
       "50             sexual        assault            sexual assault          3643   \n",
       "124494          summa            cum                 summa cum            12   \n",
       "436              card      processor            card processor           939   \n",
       "266        background         checks         background checks          1311   \n",
       "1651     battleground     prediction   battleground prediction           411   \n",
       "21065        scantily           clad             scantily clad            57   \n",
       "170           display            ads               display ads          1718   \n",
       "43847   conscientious       objector    conscientious objector            30   \n",
       "...               ...            ...                       ...           ...   \n",
       "5432             lame           duck                 lame duck           170   \n",
       "88534     homeopathic       teething      homeopathic teething            16   \n",
       "141876      inductive       coupling        inductive coupling            11   \n",
       "61936       irritable          bowel           irritable bowel            23   \n",
       "1045     conventional         wisdom       conventional wisdom           548   \n",
       "879             inner         circle              inner circle           612   \n",
       "2435             quid            pro                  quid pro           312   \n",
       "74251         rotator           cuff              rotator cuff            19   \n",
       "7763      involuntary   manslaughter  involuntary manslaughter           129   \n",
       "6788      genetically     engineered    genetically engineered           144   \n",
       "24089         grossly   generalistic      grossly generalistic            51   \n",
       "134          chemical        weapons          chemical weapons          1892   \n",
       "268695       graphing    calculators      graphing calculators             6   \n",
       "107810       untitled     unmastered       untitled unmastered            14   \n",
       "223             voter          fraud               voter fraud          1487   \n",
       "16292        wreaking          havoc            wreaking havoc            71   \n",
       "193            credit           card               credit card          1606   \n",
       "15205          bumper       stickers           bumper stickers            75   \n",
       "247             hedge           fund                hedge fund          1373   \n",
       "21609           maple          syrup               maple syrup            56   \n",
       "8758         sparsely      populated        sparsely populated           117   \n",
       "5231            bully         pulpit              bully pulpit           175   \n",
       "14082          bumper        sticker            bumper sticker            80   \n",
       "4734             soap          opera                soap opera           189   \n",
       "6414         downward         spiral           downward spiral           150   \n",
       "1047        expanding       stimulus        expanding stimulus           547   \n",
       "424            mental        illness            mental illness           950   \n",
       "242378         aortic       aneurysm           aortic aneurysm             6   \n",
       "225068         photon      thrusters          photon thrusters             7   \n",
       "140141       noblesse         oblige           noblesse oblige            11   \n",
       "\n",
       "        freq_one  freq_two  mean_freq_ratio  \n",
       "2565        1029       982         0.299354  \n",
       "15222         99       404         0.298211  \n",
       "2555         823      1247         0.292754  \n",
       "105         9569      4896         0.292153  \n",
       "5055         318       918         0.291262  \n",
       "176588        11        51         0.290323  \n",
       "1843        2037       615         0.289593  \n",
       "21056        162       232         0.289340  \n",
       "51308         31       157         0.287234  \n",
       "97263         44        61         0.285714  \n",
       "195212        45        11         0.285714  \n",
       "247290        35         7         0.285714  \n",
       "182         3585      8139         0.285227  \n",
       "3868         687       863         0.283871  \n",
       "174         9788      2213         0.282810  \n",
       "141229        24        55         0.278481  \n",
       "3633         660      1037         0.274602  \n",
       "17125        413        83         0.274194  \n",
       "187709        25        34         0.271186  \n",
       "213884        42        10         0.269231  \n",
       "4725         496       918         0.268741  \n",
       "58050         57       123         0.266667  \n",
       "50         16271     11159         0.265622  \n",
       "124494        29        62         0.263736  \n",
       "436         6026      1180         0.260616  \n",
       "266         6429      3651         0.260119  \n",
       "1651        1868      1298         0.259634  \n",
       "21065         68       374         0.257919  \n",
       "170         5254      8139         0.256552  \n",
       "43847        192        43         0.255319  \n",
       "...          ...       ...              ...  \n",
       "5432         417      1070         0.228648  \n",
       "88534         65        76         0.226950  \n",
       "141876        31        66         0.226804  \n",
       "61936         87       118         0.224390  \n",
       "1045        2818      2071         0.224177  \n",
       "879         2521      2982         0.222424  \n",
       "2435         379      2441         0.221277  \n",
       "74251         22       151         0.219653  \n",
       "7763         389       786         0.219574  \n",
       "6788         687       625         0.219512  \n",
       "24089        410        58         0.217949  \n",
       "134         5070     12434         0.216179  \n",
       "268695        10        46         0.214286  \n",
       "107810       112        19         0.213740  \n",
       "223         7798      6246         0.211763  \n",
       "16292         99       572         0.211624  \n",
       "193         9157      6026         0.211552  \n",
       "15205        348       365         0.210379  \n",
       "247         2612     10447         0.210276  \n",
       "21609        244       289         0.210131  \n",
       "8758         198       918         0.209677  \n",
       "5231        1258       415         0.209205  \n",
       "14082        348       419         0.208605  \n",
       "4734         706      1114         0.207692  \n",
       "6414         706       744         0.206897  \n",
       "1047        3668      1623         0.206766  \n",
       "424         6420      2879         0.204323  \n",
       "242378        20        39         0.203390  \n",
       "225068        23        46         0.202899  \n",
       "140141        15        94         0.201835  \n",
       "\n",
       "[89 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[(new_df.mean_freq_ratio < .3) & (new_df.mean_freq_ratio > .2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Part of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lem = WordNetLemmatizer()\n",
    "# lem_words = {}\n",
    "# for x in df.word.values:    \n",
    "#     pos = nltk.pos_tag([x])\n",
    "#     for w,p in pos:\n",
    "#         p_new = get_wordnet_pos(p)\n",
    "#         d = lem.lemmatize(w,p_new)\n",
    "#     lem_words[x] = d    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "#     if treebank_tag.startswith('J'):\n",
    "#         return wordnet.ADJ\n",
    "#     elif treebank_tag.startswith('V'):\n",
    "#         return wordnet.VERB\n",
    "#     elif treebank_tag.startswith('N'):\n",
    "#         return wordnet.NOUN\n",
    "#     elif treebank_tag.startswith('R'):\n",
    "#         return wordnet.ADV\n",
    "#     else:\n",
    "#         return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for w,p in pos:\n",
    "#     p_new = get_wordnet_pos(p)\n",
    "#     lemmed_words.append(lem.lemmatize(w,p_new))\n",
    "#     lemmed_sentence += (w + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w1 = split_df.w_one.replace(lem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2 = split_df.w_two.replace(lem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_df['w1'] = w1\n",
    "# split_df['w2'] = w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have DF with row for every phrase. \n",
    "### Now make one with every word occuring in all phrases\n",
    "### Count how often each word occurs as first, how often it occurs second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_count = Counter(split_df.w_one.values)\n",
    "w2_count = Counter(split_df.w_two.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = w1_count + w2_count\n",
    "words_inc = list(set(word_count.keys()))\n",
    "df = pd.DataFrame(words_inc, columns=['word'])\n",
    "df['start_count'] = df.word.apply(lambda x: w1_count[x])\n",
    "df['end_count'] = df.word.apply(lambda x: w2_count[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22842, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nix_words = ['made', 'make', 'making', 'liking', 'looking', 'like', 'liked', 'likes', \n",
    "             'many', 'even', 'though', 'look', 'looks', 'looked', 'take', 'took', 'know', \n",
    "             'knew', 'knows', 'say', 'said', 'go', 'got', 'much', 'often', 'who', 'whom', \n",
    "             'whose', 'their', 'theirs', 'dozen', 'might', 'may', 'never', 'also', 'still',\n",
    "             'expressed', 'went', 'expresses', 'express', 'expressing', 'saying', 'u']\n",
    "\n",
    "'''\n",
    "when, where, why, that\n",
    "\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.word.isin(nix_words)]\n",
    "split_df = split_df[~split_df.w_two.isin(nix_words)]\n",
    "split_df = split_df[~split_df.w_one.isin(nix_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89479, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_count'] = df.word.apply(lambda x: split_df[split_df.w_one==x]['w_one'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['end_count'] = df.word.apply(lambda x: split_df[split_df.w_two==x]['w_two'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.start_count > 3)&(df.end_count > 3)]\n",
    "# print(df.shape)\n",
    "# df = df[df.end_count > 7]\n",
    "# print(df.shape)\n",
    "# df = df[df.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df = split_df[split_df.w_one.isin(df.word.values)]\n",
    "split_df = split_df[split_df.w_two.isin(df.word.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53133, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv = split_df.loc[:,['phrases', 'w1', 'w2']].sort_values(['w1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv.to_csv('phrase_list.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe remove:\n",
    "made, make, like, many, even, though, first, look, time, (prepositions??) , take, used, using, use, say, know, le, get, much, go, got, often, who, whose, dozen, might, may, never, also, say, seem, still, express, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2197, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['before'] = df.word.apply(lambda x: split_df[split_df.w_two == x].w_one.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['after'] = df.word.apply(lambda x: split_df[split_df.w_one == x].w_two.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69003"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.end_count.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test lem word replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['word_test'] = df.word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.word_test = df.word_test.replace(lem_words)\n",
    "# df.word_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct_dict = df.groupby('word_test').count().word.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['repeats'] = df.word_test.replace(ct_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>start_count</th>\n",
       "      <th>end_count</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>management</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>[team, company, style, firm, system, fee, skil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>normal</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>[life, people, time, person, level, human, rul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>written</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>[statement, testimony, response, question, boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wounded</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>[people, soldier, officer, veteran, man, hundr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>born</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>[citizen, outside, without, classified, female...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  start_count  end_count  \\\n",
       "6   management           24         26   \n",
       "8       normal           43         12   \n",
       "13     written           23         27   \n",
       "14     wounded            9         11   \n",
       "21        born           10         17   \n",
       "\n",
       "                                                after  \n",
       "6   [team, company, style, firm, system, fee, skil...  \n",
       "8   [life, people, time, person, level, human, rul...  \n",
       "13  [statement, testimony, response, question, boo...  \n",
       "14  [people, soldier, officer, veteran, man, hundr...  \n",
       "21  [citizen, outside, without, classified, female...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['all_words'] = df.start_count + df.end_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>start_count</th>\n",
       "      <th>end_count</th>\n",
       "      <th>after</th>\n",
       "      <th>all_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7469</th>\n",
       "      <td>new</td>\n",
       "      <td>901</td>\n",
       "      <td>225</td>\n",
       "      <td>[book, administration, president, study, repor...</td>\n",
       "      <td>1126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>people</td>\n",
       "      <td>528</td>\n",
       "      <td>504</td>\n",
       "      <td>[want, think, around, feel, died, dead, living...</td>\n",
       "      <td>1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8845</th>\n",
       "      <td>political</td>\n",
       "      <td>590</td>\n",
       "      <td>201</td>\n",
       "      <td>[party, analyst, system, leader, class, news, ...</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>first</td>\n",
       "      <td>638</td>\n",
       "      <td>70</td>\n",
       "      <td>[time, place, reported, step, half, round, thi...</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>another</td>\n",
       "      <td>441</td>\n",
       "      <td>153</td>\n",
       "      <td>[way, person, example, man, country, woman, re...</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>last</td>\n",
       "      <td>174</td>\n",
       "      <td>405</td>\n",
       "      <td>[night, time, summer, season, fall, weekend, d...</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>without</td>\n",
       "      <td>276</td>\n",
       "      <td>300</td>\n",
       "      <td>[fear, ever, evidence, knowing, charge, gettin...</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8929</th>\n",
       "      <td>state</td>\n",
       "      <td>285</td>\n",
       "      <td>234</td>\n",
       "      <td>[law, government, medium, official, attorney, ...</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>around</td>\n",
       "      <td>46</td>\n",
       "      <td>469</td>\n",
       "      <td>[town, since, campus, half, people, long, time...</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12110</th>\n",
       "      <td>since</td>\n",
       "      <td>80</td>\n",
       "      <td>410</td>\n",
       "      <td>[last, taking, early, become, leaving, late, b...</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>get</td>\n",
       "      <td>346</td>\n",
       "      <td>131</td>\n",
       "      <td>[back, away, better, involved, along, people, ...</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>government</td>\n",
       "      <td>328</td>\n",
       "      <td>144</td>\n",
       "      <td>[official, agency, force, employee, spending, ...</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3920</th>\n",
       "      <td>public</td>\n",
       "      <td>326</td>\n",
       "      <td>136</td>\n",
       "      <td>[school, health, safety, service, policy, opin...</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>woman</td>\n",
       "      <td>209</td>\n",
       "      <td>245</td>\n",
       "      <td>[named, without, president, voter, wearing, ar...</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467</th>\n",
       "      <td>back</td>\n",
       "      <td>92</td>\n",
       "      <td>360</td>\n",
       "      <td>[home, seat, together, away, control, door, te...</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10601</th>\n",
       "      <td>every</td>\n",
       "      <td>304</td>\n",
       "      <td>146</td>\n",
       "      <td>[single, time, night, state, person, bit, turn...</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249</th>\n",
       "      <td>campaign</td>\n",
       "      <td>251</td>\n",
       "      <td>165</td>\n",
       "      <td>[rally, event, finance, official, stop, rhetor...</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7254</th>\n",
       "      <td>company</td>\n",
       "      <td>188</td>\n",
       "      <td>225</td>\n",
       "      <td>[called, announced, based, behind, executive, ...</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11946</th>\n",
       "      <td>time</td>\n",
       "      <td>170</td>\n",
       "      <td>236</td>\n",
       "      <td>[since, around, period, last, spent, soon, eve...</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9680</th>\n",
       "      <td>group</td>\n",
       "      <td>165</td>\n",
       "      <td>237</td>\n",
       "      <td>[called, known, based, including, claimed, sup...</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10360</th>\n",
       "      <td>right</td>\n",
       "      <td>167</td>\n",
       "      <td>228</td>\n",
       "      <td>[thing, group, away, activist, movement, way, ...</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>policy</td>\n",
       "      <td>183</td>\n",
       "      <td>210</td>\n",
       "      <td>[adviser, change, issue, toward, position, pro...</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9773</th>\n",
       "      <td>official</td>\n",
       "      <td>268</td>\n",
       "      <td>122</td>\n",
       "      <td>[confirmed, believe, statement, state, governm...</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11143</th>\n",
       "      <td>really</td>\n",
       "      <td>329</td>\n",
       "      <td>53</td>\n",
       "      <td>[good, want, hard, need, important, think, bad...</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>good</td>\n",
       "      <td>292</td>\n",
       "      <td>90</td>\n",
       "      <td>[news, thing, job, reason, idea, enough, time,...</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>among</td>\n",
       "      <td>121</td>\n",
       "      <td>254</td>\n",
       "      <td>[others, white, voter, woman, black, people, y...</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>le</td>\n",
       "      <td>235</td>\n",
       "      <td>121</td>\n",
       "      <td>[likely, money, safe, expensive, time, importa...</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6018</th>\n",
       "      <td>police</td>\n",
       "      <td>214</td>\n",
       "      <td>126</td>\n",
       "      <td>[officer, department, chief, shooting, force, ...</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11452</th>\n",
       "      <td>great</td>\n",
       "      <td>296</td>\n",
       "      <td>40</td>\n",
       "      <td>[story, deal, thing, job, people, country, nat...</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>several</td>\n",
       "      <td>232</td>\n",
       "      <td>102</td>\n",
       "      <td>[time, hundred, hour, people, decade, state, r...</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>earn</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>[money, le, enough, back]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6856</th>\n",
       "      <td>deny</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>[service, entry, coverage, whether, people]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11549</th>\n",
       "      <td>resigned</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>[last, amid, rather, following, earlier]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10993</th>\n",
       "      <td>compromise</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>[kept, bill, candidate, national, measure]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>chocolate</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>[chip, bar, factory]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>mail</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>[message, fraud, truck]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>startup</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>[called, company, world]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9758</th>\n",
       "      <td>ranking</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>[member, system, point, official]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4470</th>\n",
       "      <td>subpoena</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[power, issued, related]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>creates</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[new, job, regarding, problem]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>exhibition</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[game, space, hall, season]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9433</th>\n",
       "      <td>passport</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[control, photo, application]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3074</th>\n",
       "      <td>picking</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[fight, side]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11321</th>\n",
       "      <td>panic</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[attack, among]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11936</th>\n",
       "      <td>jumped</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[onto, back, ship]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8701</th>\n",
       "      <td>comeback</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[victory, story, win]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8710</th>\n",
       "      <td>knee</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[injury, replacement, pain]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8744</th>\n",
       "      <td>slip</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[away, back, dress, past]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7201</th>\n",
       "      <td>parliament</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[building, voted, member, passed]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>rely</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[heavily, upon, solely, le]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>edited</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[video]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11923</th>\n",
       "      <td>scholarship</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[program, fund, money, offer]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7753</th>\n",
       "      <td>downtown</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[area, street, hotel, office]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6950</th>\n",
       "      <td>asks</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[whether, people, voter, question]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6932</th>\n",
       "      <td>riot</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[police, broke]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9032</th>\n",
       "      <td>log</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[show, back, onto]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116</th>\n",
       "      <td>cream</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[shop, truck]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>heavyweight</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[title, championship]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6855</th>\n",
       "      <td>disclose</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[meeting, information, payment, detail]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7288</th>\n",
       "      <td>library</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[card, book, director, system]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2197 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  start_count  end_count  \\\n",
       "7469           new          901        225   \n",
       "1874        people          528        504   \n",
       "8845     political          590        201   \n",
       "372          first          638         70   \n",
       "4815       another          441        153   \n",
       "120           last          174        405   \n",
       "1129       without          276        300   \n",
       "8929         state          285        234   \n",
       "842         around           46        469   \n",
       "12110        since           80        410   \n",
       "936            get          346        131   \n",
       "1555    government          328        144   \n",
       "3920        public          326        136   \n",
       "5947         woman          209        245   \n",
       "6467          back           92        360   \n",
       "10601        every          304        146   \n",
       "6249      campaign          251        165   \n",
       "7254       company          188        225   \n",
       "11946         time          170        236   \n",
       "9680         group          165        237   \n",
       "10360        right          167        228   \n",
       "1782        policy          183        210   \n",
       "9773      official          268        122   \n",
       "11143       really          329         53   \n",
       "2425          good          292         90   \n",
       "4901         among          121        254   \n",
       "1295            le          235        121   \n",
       "6018        police          214        126   \n",
       "11452        great          296         40   \n",
       "3485       several          232        102   \n",
       "...            ...          ...        ...   \n",
       "4867          earn            5          4   \n",
       "6856          deny            5          4   \n",
       "11549     resigned            5          4   \n",
       "10993   compromise            5          4   \n",
       "3850     chocolate            5          4   \n",
       "1614          mail            4          5   \n",
       "2852       startup            4          5   \n",
       "9758       ranking            4          5   \n",
       "4470      subpoena            4          4   \n",
       "5109       creates            4          4   \n",
       "3473    exhibition            4          4   \n",
       "9433      passport            4          4   \n",
       "3074       picking            4          4   \n",
       "11321        panic            4          4   \n",
       "11936       jumped            4          4   \n",
       "8701      comeback            4          4   \n",
       "8710          knee            4          4   \n",
       "8744          slip            4          4   \n",
       "7201    parliament            4          4   \n",
       "2610          rely            4          4   \n",
       "2156        edited            4          4   \n",
       "11923  scholarship            4          4   \n",
       "7753      downtown            4          4   \n",
       "6950          asks            4          4   \n",
       "6932          riot            4          4   \n",
       "9032           log            4          4   \n",
       "3116         cream            4          4   \n",
       "4079   heavyweight            4          4   \n",
       "6855      disclose            4          4   \n",
       "7288       library            4          4   \n",
       "\n",
       "                                                   after  all_words  \n",
       "7469   [book, administration, president, study, repor...       1126  \n",
       "1874   [want, think, around, feel, died, dead, living...       1032  \n",
       "8845   [party, analyst, system, leader, class, news, ...        791  \n",
       "372    [time, place, reported, step, half, round, thi...        708  \n",
       "4815   [way, person, example, man, country, woman, re...        594  \n",
       "120    [night, time, summer, season, fall, weekend, d...        579  \n",
       "1129   [fear, ever, evidence, knowing, charge, gettin...        576  \n",
       "8929   [law, government, medium, official, attorney, ...        519  \n",
       "842    [town, since, campus, half, people, long, time...        515  \n",
       "12110  [last, taking, early, become, leaving, late, b...        490  \n",
       "936    [back, away, better, involved, along, people, ...        477  \n",
       "1555   [official, agency, force, employee, spending, ...        472  \n",
       "3920   [school, health, safety, service, policy, opin...        462  \n",
       "5947   [named, without, president, voter, wearing, ar...        454  \n",
       "6467   [home, seat, together, away, control, door, te...        452  \n",
       "10601  [single, time, night, state, person, bit, turn...        450  \n",
       "6249   [rally, event, finance, official, stop, rhetor...        416  \n",
       "7254   [called, announced, based, behind, executive, ...        413  \n",
       "11946  [since, around, period, last, spent, soon, eve...        406  \n",
       "9680   [called, known, based, including, claimed, sup...        402  \n",
       "10360  [thing, group, away, activist, movement, way, ...        395  \n",
       "1782   [adviser, change, issue, toward, position, pro...        393  \n",
       "9773   [confirmed, believe, statement, state, governm...        390  \n",
       "11143  [good, want, hard, need, important, think, bad...        382  \n",
       "2425   [news, thing, job, reason, idea, enough, time,...        382  \n",
       "4901   [others, white, voter, woman, black, people, y...        375  \n",
       "1295   [likely, money, safe, expensive, time, importa...        356  \n",
       "6018   [officer, department, chief, shooting, force, ...        340  \n",
       "11452  [story, deal, thing, job, people, country, nat...        336  \n",
       "3485   [time, hundred, hour, people, decade, state, r...        334  \n",
       "...                                                  ...        ...  \n",
       "4867                           [money, le, enough, back]          9  \n",
       "6856         [service, entry, coverage, whether, people]          9  \n",
       "11549           [last, amid, rather, following, earlier]          9  \n",
       "10993         [kept, bill, candidate, national, measure]          9  \n",
       "3850                                [chip, bar, factory]          9  \n",
       "1614                             [message, fraud, truck]          9  \n",
       "2852                            [called, company, world]          9  \n",
       "9758                   [member, system, point, official]          9  \n",
       "4470                            [power, issued, related]          8  \n",
       "5109                      [new, job, regarding, problem]          8  \n",
       "3473                         [game, space, hall, season]          8  \n",
       "9433                       [control, photo, application]          8  \n",
       "3074                                       [fight, side]          8  \n",
       "11321                                    [attack, among]          8  \n",
       "11936                                 [onto, back, ship]          8  \n",
       "8701                               [victory, story, win]          8  \n",
       "8710                         [injury, replacement, pain]          8  \n",
       "8744                           [away, back, dress, past]          8  \n",
       "7201                   [building, voted, member, passed]          8  \n",
       "2610                         [heavily, upon, solely, le]          8  \n",
       "2156                                             [video]          8  \n",
       "11923                      [program, fund, money, offer]          8  \n",
       "7753                       [area, street, hotel, office]          8  \n",
       "6950                  [whether, people, voter, question]          8  \n",
       "6932                                     [police, broke]          8  \n",
       "9032                                  [show, back, onto]          8  \n",
       "3116                                       [shop, truck]          8  \n",
       "4079                               [title, championship]          8  \n",
       "6855             [meeting, information, payment, detail]          8  \n",
       "7288                      [card, book, director, system]          8  \n",
       "\n",
       "[2197 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['all_words'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Examples of why this lemma doesn't work -- adopted home --> adopt home ; disappointing result --> disappoint result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### don't think this adds anything new, same as other column...\n",
    "\n",
    "#df['num_after'] = df.after.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_count</th>\n",
       "      <th>end_count</th>\n",
       "      <th>after</th>\n",
       "      <th>all_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>management</th>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>[team, company, style, firm, system, fee, skil...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>[life, people, time, person, level, human, rul...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>written</th>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>[statement, testimony, response, question, boo...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wounded</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>[people, soldier, officer, veteran, man, hundr...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>born</th>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>[citizen, outside, without, classified, female...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star</th>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>[power, player, turn, system, witness, turned,...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>provides</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>[free, service, expert, additional, support, a...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global</th>\n",
       "      <td>162</td>\n",
       "      <td>25</td>\n",
       "      <td>[economy, market, financial, temperature, trad...</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>89</td>\n",
       "      <td>185</td>\n",
       "      <td>[among, group, behind, system, staff, network,...</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bar</th>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>[citizen, owner, entry, people, elected, fight...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mile</th>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>[away, per, north, south, east, west, outside,...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daily</th>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>[life, briefing, press, newspaper, routine, in...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disabled</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>[list, people, reporter, child, veteran, perso...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>martial</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>[art, law, artist, beat]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>legally</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>[required, allowed, responsible, changed, poss...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gave</th>\n",
       "      <td>26</td>\n",
       "      <td>38</td>\n",
       "      <td>[birth, way, rise, away, money, speech, people...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single</th>\n",
       "      <td>114</td>\n",
       "      <td>17</td>\n",
       "      <td>[mother, market, person, woman, parent, word, ...</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>militia</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>[group, member, leader, fighter, fighting, for...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employer</th>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>[plan, coverage, added, must, pay]</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>due</th>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>[process, back, date, course, time, next, late...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            start_count  end_count  \\\n",
       "word                                 \n",
       "management           24         26   \n",
       "normal               43         12   \n",
       "written              23         27   \n",
       "wounded               9         11   \n",
       "born                 10         17   \n",
       "star                 24         58   \n",
       "provides             18          8   \n",
       "global              162         25   \n",
       "support              89        185   \n",
       "bar                  18         38   \n",
       "mile                 22         11   \n",
       "daily                40          8   \n",
       "disabled             10          5   \n",
       "martial               4          5   \n",
       "legally              30          4   \n",
       "gave                 26         38   \n",
       "single              114         17   \n",
       "militia               8          6   \n",
       "employer              7         18   \n",
       "due                  10         41   \n",
       "\n",
       "                                                        after  all_words  \n",
       "word                                                                      \n",
       "management  [team, company, style, firm, system, fee, skil...         50  \n",
       "normal      [life, people, time, person, level, human, rul...         55  \n",
       "written     [statement, testimony, response, question, boo...         50  \n",
       "wounded     [people, soldier, officer, veteran, man, hundr...         20  \n",
       "born        [citizen, outside, without, classified, female...         27  \n",
       "star        [power, player, turn, system, witness, turned,...         82  \n",
       "provides    [free, service, expert, additional, support, a...         26  \n",
       "global      [economy, market, financial, temperature, trad...        187  \n",
       "support     [among, group, behind, system, staff, network,...        274  \n",
       "bar         [citizen, owner, entry, people, elected, fight...         56  \n",
       "mile        [away, per, north, south, east, west, outside,...         33  \n",
       "daily       [life, briefing, press, newspaper, routine, in...         48  \n",
       "disabled    [list, people, reporter, child, veteran, perso...         15  \n",
       "martial                              [art, law, artist, beat]          9  \n",
       "legally     [required, allowed, responsible, changed, poss...         34  \n",
       "gave        [birth, way, rise, away, money, speech, people...         64  \n",
       "single      [mother, market, person, woman, parent, word, ...        131  \n",
       "militia     [group, member, leader, fighter, fighting, for...         14  \n",
       "employer                   [plan, coverage, added, must, pay]         25  \n",
       "due         [process, back, date, course, time, next, late...         51  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df.set_index(df.word).drop('word', axis=1)\n",
    "new_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head(50).to_csv('top50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2_filt = { x: count for x, count in w2_count.items() if w2_count[x] >= 10 }\n",
    "# w1_filt = { x: count for x, count in w1_count.items() if w1_count[x] >= 10 }\n",
    "# print(len(w2_filt))\n",
    "# print(len(w1_filt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame([df.word, df.after]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df.set_index(temp_df.word).drop('word', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict0 = temp_df.T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {k:v[0].tolist() for k, v in word_dict0.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temp_dict.pickle', 'wb') as outputfile:\n",
    "    pickle.dump(word_dict, outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pick key randomly\n",
    "word_list = []\n",
    "word1 = random.choice(list(word_dict.keys()))\n",
    "word_list.append(word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_new(l_word, word_list):\n",
    "    rng = list(range(len(word_dict[l_word])))\n",
    "    random.shuffle(rng)\n",
    "    random.shuffle(rng)\n",
    "    choices = list(np.array(word_dict[l_word])[rng])\n",
    "    for i in range(len(choices)):\n",
    "        l = len(choices)\n",
    "        if l > 0:\n",
    "            if choices[i] in word_dict.keys():\n",
    "                if choices[i] not in word_list:\n",
    "                    new_word = choices[i]\n",
    "                    word_list.append(new_word)\n",
    "                    break\n",
    "                else:\n",
    "                    choices.remove(choices[i])\n",
    "        else:\n",
    "            raise InputError('No choices left')\n",
    "    return new_word, word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Eliminate repeats to avoid :\n",
    "\n",
    "Dogs \n",
    "Walk\n",
    "Dogs\n",
    "Walk\n",
    "...\n",
    "\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_set():\n",
    "    word_list = []\n",
    "    word1 = random.choice(list(word_dict.keys()))\n",
    "    word_list.append(word1)\n",
    "    \n",
    "    word2, word_list = pick_new(word1, word_list)\n",
    "    word3, word_list = pick_new(word2, word_list)\n",
    "    word4, word_list = pick_new(word3, word_list)\n",
    "    word5, word_list = pick_new(word4, word_list)\n",
    "    word6, word_list = pick_new(word5, word_list)\n",
    "    word7, word_list = pick_new(word6, word_list)\n",
    "    word8, word_list = pick_new(word7, word_list)\n",
    "    word9, word_list = pick_new(word8, word_list)\n",
    "    word10, word_list = pick_new(word9, word_list)\n",
    "    return word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = pick_set()\n",
    "list2 = pick_set()\n",
    "list3 = pick_set()\n",
    "list4 = pick_set()\n",
    "list5 = pick_set()\n",
    "list6 = pick_set()\n",
    "list7 = pick_set()\n",
    "list8 = pick_set()\n",
    "list9 = pick_set()\n",
    "list10 = pick_set()\n",
    "list11 = pick_set()\n",
    "list12 = pick_set()\n",
    "list13 = pick_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'statement', 'later', 'allowed', 'people', 'fought', 'hard', 'thing', 'become', 'president']\n",
      "['terrorist', 'crime', 'rose', 'gold', 'standard', 'regarding', 'immigration', 'enforcement', 'activity', 'outside']\n",
      "['eating', 'dinner', 'party', 'already', 'talking', 'politics', 'right', 'man', 'started', 'training']\n",
      "['simply', 'call', 'ended', 'without', 'trying', 'new', 'history', 'department', 'need', 'today']\n",
      "['comment', 'came', 'away', 'money', 'talk', 'begin', 'work', 'closely', 'followed', 'suit']\n",
      "['seem', 'increasingly', 'turned', 'head', 'next', 'meet', 'weekly', 'column', 'called', 'cop']\n",
      "['positive', 'note', 'taken', 'inside', 'story', 'straight', 'man', 'fell', 'sharply', 'cut']\n",
      "['bankruptcy', 'last', 'winter', 'blue', 'blood', 'test', 'run', 'without', 'anything', 'unusual']\n",
      "['household', 'item', 'including', 'cutting', 'deal', 'since', 'news', 'agenda', 'without', 'receiving']\n",
      "['shot', 'behind', 'bar', 'elected', 'lawmaker', 'last', 'good', 'effect', 'immediately', 'attracted']\n",
      "['scholarship', 'fund', 'abortion', 'per', 'season', 'began', 'coming', 'together', 'every', 'female']\n",
      "['educated', 'person', 'per', 'user', 'experience', 'via', 'trade', 'data', 'regarding', 'illegal']\n",
      "['half', 'time', 'machine', 'gun', 'via', 'social', 'network', 'security', 'crisis', 'point']\n"
     ]
    }
   ],
   "source": [
    "print(list1)\n",
    "print(list2)\n",
    "print(list3)\n",
    "print(list4)\n",
    "print(list5)\n",
    "print(list6)\n",
    "print(list7)\n",
    "print(list8)\n",
    "print(list9)\n",
    "print(list10)\n",
    "print(list11)\n",
    "print(list12)\n",
    "print(list13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'released'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2, word_list = pick_new(word1, word_list)\n",
    "word2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'immediately'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word3, word_list = pick_new(word2, word_list)\n",
    "word3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'upon'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word4, word_list = pick_new(word3, word_list)\n",
    "word4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'release'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word5, word_list = pick_new(word4, word_list)\n",
    "word5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'video'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word6, word_list = pick_new(word5, word_list)\n",
    "word6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'game'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word7, word_list = pick_new(word6, word_list)\n",
    "word7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'behind'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word8, word_list = pick_new(word7, word_list)\n",
    "word8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wall'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word9, word_list = pick_new(word8, word_list)\n",
    "word9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'around'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word10, word_list = pick_new(word9, word_list)\n",
    "word10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
