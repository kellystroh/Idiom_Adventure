{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get phrase counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('counter_Z.pickle', 'rb') as inputfile:\n",
    "    a = pickle.load(inputfile)\n",
    "with open('counter_Z2.pickle', 'rb') as inputfile:\n",
    "    b = pickle.load(inputfile)\n",
    "with open('counter_Z3.pickle', 'rb') as inputfile:\n",
    "    c = pickle.load(inputfile)\n",
    "with open('counter_Z4.pickle', 'rb') as inputfile:\n",
    "    d = pickle.load(inputfile)\n",
    "with open('counter_Z5.pickle', 'rb') as inputfile:\n",
    "    e = pickle.load(inputfile)\n",
    "with open('counter_Z6.pickle', 'rb') as inputfile:\n",
    "    f = pickle.load(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_counter = a + b + c + d + e + f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top300k = phrase_counter.most_common(300000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = scipy.sparse.load_npz('count_vect.npz')\n",
    "feat_vect = np.load('vect_feat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = {'word': feat_vect, 'count':count_vect.sum(axis = 0).tolist()[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = pd.DataFrame(count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = count_df.set_index('word', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>2463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>60512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000000</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count\n",
       "word          \n",
       "00        2463\n",
       "000      60512\n",
       "0000        26\n",
       "00000        4\n",
       "0000000      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = count_df.to_dict()['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(top300k)\n",
    "df300k = pd.DataFrame(data=arr, columns=['phrases', 'counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df = df300k.phrases.str.split(' ', expand=True)\n",
    "split_df['phrases'] = df300k.phrases\n",
    "split_df['phrase_count'] = df300k.counts.astype(int)\n",
    "split_df.rename(columns={0:'w_one', 1:'w_two'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_one</th>\n",
       "      <th>w_two</th>\n",
       "      <th>phrases</th>\n",
       "      <th>phrase_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last</td>\n",
       "      <td>year</td>\n",
       "      <td>last year</td>\n",
       "      <td>22402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>last</td>\n",
       "      <td>week</td>\n",
       "      <td>last week</td>\n",
       "      <td>16826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>years</td>\n",
       "      <td>ago</td>\n",
       "      <td>years ago</td>\n",
       "      <td>15663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>social</td>\n",
       "      <td>media</td>\n",
       "      <td>social media</td>\n",
       "      <td>11830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first</td>\n",
       "      <td>time</td>\n",
       "      <td>first time</td>\n",
       "      <td>11712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    w_one  w_two       phrases  phrase_count\n",
       "0    last   year     last year         22402\n",
       "1    last   week     last week         16826\n",
       "2   years    ago     years ago         15663\n",
       "3  social  media  social media         11830\n",
       "4   first   time    first time         11712"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglish(s):\n",
    "    return s.isascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_english = split_df[~split_df.phrases.apply(lambda x: isEnglish(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df = split_df[split_df.phrases.apply(lambda x: isEnglish(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calc how frequently a word occurs in common phrases\n",
    "# word_one = split_df.groupby(split_df.w_one)['phrase_count'].sum().to_dict()\n",
    "# word_two = split_df.groupby(split_df.w_two)['phrase_count'].sum().to_dict()\n",
    "\n",
    "# for word in list(word_one.keys()):\n",
    "#     if word not in word_two:\n",
    "#         word_two[word] = 0\n",
    "        \n",
    "# for word in list(word_two.keys()):\n",
    "#     if word not in word_one:\n",
    "#         word_one[word] = 0\n",
    "\n",
    "# md = {k: int(word_one[k]) + int(word_two[k]) for k in set(list(word_one.keys()) + list(word_two.keys()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = set(list(split_df.w_one) + list(split_df.w_two))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_df = pd.DataFrame(list(words), columns=['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_df = word_df[word_df.word.apply(lambda x: len(x)) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df = split_df[split_df.w_one.apply(lambda x: len(x)) > 2]\n",
    "split_df = split_df[split_df.w_two.apply(lambda x: len(x)) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df['freq_one'] = split_df.w_one.apply(lambda x: freq_dict[x])\n",
    "split_df['freq_two'] = split_df.w_two.apply(lambda x: freq_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df['mean_freq_ratio'] = split_df.phrase_count / ((split_df.freq_one + split_df.freq_two)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "infinity = split_df[split_df.mean_freq_ratio > 10].index\n",
    "split_df.drop(infinity, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1000 = split_df.mean_freq_ratio.nlargest(1000).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([172474, 334844, 374190, 375243, 382393, 383149, 396152, 479748,\n",
       "            498110, 576352,\n",
       "            ...\n",
       "            765145, 957290, 957291,    529,   1843,  12098, 308085, 609781,\n",
       "            665585,  13683],\n",
       "           dtype='int64', length=1000)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_one</th>\n",
       "      <th>w_two</th>\n",
       "      <th>phrases</th>\n",
       "      <th>phrase_count</th>\n",
       "      <th>freq_one</th>\n",
       "      <th>freq_two</th>\n",
       "      <th>mean_freq_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172474</th>\n",
       "      <td>karē</td>\n",
       "      <td>raisu</td>\n",
       "      <td>karē raisu</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334844</th>\n",
       "      <td>hemolytic</td>\n",
       "      <td>uremic</td>\n",
       "      <td>hemolytic uremic</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374190</th>\n",
       "      <td>llanura</td>\n",
       "      <td>aluvial</td>\n",
       "      <td>llanura aluvial</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375243</th>\n",
       "      <td>rumah</td>\n",
       "      <td>gadang</td>\n",
       "      <td>rumah gadang</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382393</th>\n",
       "      <td>prolate</td>\n",
       "      <td>spheroid</td>\n",
       "      <td>prolate spheroid</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383149</th>\n",
       "      <td>barbeled</td>\n",
       "      <td>dragonfishes</td>\n",
       "      <td>barbeled dragonfishes</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396152</th>\n",
       "      <td>latissimus</td>\n",
       "      <td>dorsi</td>\n",
       "      <td>latissimus dorsi</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479748</th>\n",
       "      <td>maar</td>\n",
       "      <td>gewoon</td>\n",
       "      <td>maar gewoon</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498110</th>\n",
       "      <td>polychlorinated</td>\n",
       "      <td>biphenyls</td>\n",
       "      <td>polychlorinated biphenyls</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576352</th>\n",
       "      <td>truncus</td>\n",
       "      <td>arteriosus</td>\n",
       "      <td>truncus arteriosus</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613783</th>\n",
       "      <td>substantia</td>\n",
       "      <td>nigra</td>\n",
       "      <td>substantia nigra</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620882</th>\n",
       "      <td>panim</td>\n",
       "      <td>chadashot</td>\n",
       "      <td>panim chadashot</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682121</th>\n",
       "      <td>polymyalgia</td>\n",
       "      <td>rheumatica</td>\n",
       "      <td>polymyalgia rheumatica</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728106</th>\n",
       "      <td>avda</td>\n",
       "      <td>tikvateinu</td>\n",
       "      <td>avda tikvateinu</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738746</th>\n",
       "      <td>dolus</td>\n",
       "      <td>eventualis</td>\n",
       "      <td>dolus eventualis</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766596</th>\n",
       "      <td>ankylosing</td>\n",
       "      <td>spondylitis</td>\n",
       "      <td>ankylosing spondylitis</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807631</th>\n",
       "      <td>unius</td>\n",
       "      <td>libri</td>\n",
       "      <td>unius libri</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836873</th>\n",
       "      <td>duces</td>\n",
       "      <td>tecum</td>\n",
       "      <td>duces tecum</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850287</th>\n",
       "      <td>schwer</td>\n",
       "      <td>getroffen</td>\n",
       "      <td>schwer getroffen</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873504</th>\n",
       "      <td>cursus</td>\n",
       "      <td>honorum</td>\n",
       "      <td>cursus honorum</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876797</th>\n",
       "      <td>huwag</td>\n",
       "      <td>tularan</td>\n",
       "      <td>huwag tularan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889527</th>\n",
       "      <td>wishy</td>\n",
       "      <td>washy</td>\n",
       "      <td>wishy washy</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932236</th>\n",
       "      <td>creas</td>\n",
       "      <td>ingly</td>\n",
       "      <td>creas ingly</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950841</th>\n",
       "      <td>avrà</td>\n",
       "      <td>lunga</td>\n",
       "      <td>avrà lunga</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950842</th>\n",
       "      <td>lunga</td>\n",
       "      <td>gestione</td>\n",
       "      <td>lunga gestione</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951093</th>\n",
       "      <td>garantiremo</td>\n",
       "      <td>ricostruzione</td>\n",
       "      <td>garantiremo ricostruzione</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957289</th>\n",
       "      <td>paesi</td>\n",
       "      <td>colpiti</td>\n",
       "      <td>paesi colpiti</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971550</th>\n",
       "      <td>flagrante</td>\n",
       "      <td>delicto</td>\n",
       "      <td>flagrante delicto</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975884</th>\n",
       "      <td>cheggar</td>\n",
       "      <td>yellum</td>\n",
       "      <td>cheggar yellum</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981270</th>\n",
       "      <td>damnatio</td>\n",
       "      <td>memoriae</td>\n",
       "      <td>damnatio memoriae</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265740</th>\n",
       "      <td>whoopee</td>\n",
       "      <td>cushions</td>\n",
       "      <td>whoopee cushions</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>101</td>\n",
       "      <td>0.104348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303780</th>\n",
       "      <td>jeune</td>\n",
       "      <td>homme</td>\n",
       "      <td>jeune homme</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>81</td>\n",
       "      <td>0.104348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6623</th>\n",
       "      <td>fried</td>\n",
       "      <td>chicken</td>\n",
       "      <td>fried chicken</td>\n",
       "      <td>159</td>\n",
       "      <td>709</td>\n",
       "      <td>2342</td>\n",
       "      <td>0.104228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>ratio</td>\n",
       "      <td>favored</td>\n",
       "      <td>ratio favored</td>\n",
       "      <td>183</td>\n",
       "      <td>1305</td>\n",
       "      <td>2211</td>\n",
       "      <td>0.104096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389776</th>\n",
       "      <td>javelin</td>\n",
       "      <td>throwers</td>\n",
       "      <td>javelin throwers</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>26</td>\n",
       "      <td>0.103896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17934</th>\n",
       "      <td>operator</td>\n",
       "      <td>permissions</td>\n",
       "      <td>operator permissions</td>\n",
       "      <td>72</td>\n",
       "      <td>1248</td>\n",
       "      <td>140</td>\n",
       "      <td>0.103746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288673</th>\n",
       "      <td>anorexia</td>\n",
       "      <td>nervosa</td>\n",
       "      <td>anorexia nervosa</td>\n",
       "      <td>6</td>\n",
       "      <td>109</td>\n",
       "      <td>7</td>\n",
       "      <td>0.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6022</th>\n",
       "      <td>nominating</td>\n",
       "      <td>contests</td>\n",
       "      <td>nominating contests</td>\n",
       "      <td>172</td>\n",
       "      <td>1470</td>\n",
       "      <td>1856</td>\n",
       "      <td>0.103428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53198</th>\n",
       "      <td>itemized</td>\n",
       "      <td>deductions</td>\n",
       "      <td>itemized deductions</td>\n",
       "      <td>28</td>\n",
       "      <td>59</td>\n",
       "      <td>483</td>\n",
       "      <td>0.103321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68932</th>\n",
       "      <td>doctoral</td>\n",
       "      <td>dissertation</td>\n",
       "      <td>doctoral dissertation</td>\n",
       "      <td>22</td>\n",
       "      <td>256</td>\n",
       "      <td>170</td>\n",
       "      <td>0.103286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18014</th>\n",
       "      <td>slam</td>\n",
       "      <td>dunk</td>\n",
       "      <td>slam dunk</td>\n",
       "      <td>71</td>\n",
       "      <td>1169</td>\n",
       "      <td>208</td>\n",
       "      <td>0.103123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>initial</td>\n",
       "      <td>pledge</td>\n",
       "      <td>initial pledge</td>\n",
       "      <td>547</td>\n",
       "      <td>6582</td>\n",
       "      <td>4045</td>\n",
       "      <td>0.102945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9061</th>\n",
       "      <td>internally</td>\n",
       "      <td>displaced</td>\n",
       "      <td>internally displaced</td>\n",
       "      <td>125</td>\n",
       "      <td>712</td>\n",
       "      <td>1720</td>\n",
       "      <td>0.102796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40832</th>\n",
       "      <td>razor</td>\n",
       "      <td>blade</td>\n",
       "      <td>razor blade</td>\n",
       "      <td>35</td>\n",
       "      <td>269</td>\n",
       "      <td>412</td>\n",
       "      <td>0.102790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109957</th>\n",
       "      <td>nitty</td>\n",
       "      <td>gritty</td>\n",
       "      <td>nitty gritty</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>274</td>\n",
       "      <td>0.102740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4209</th>\n",
       "      <td>currency</td>\n",
       "      <td>manipulation</td>\n",
       "      <td>currency manipulation</td>\n",
       "      <td>226</td>\n",
       "      <td>3605</td>\n",
       "      <td>798</td>\n",
       "      <td>0.102657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>oral</td>\n",
       "      <td>arguments</td>\n",
       "      <td>oral arguments</td>\n",
       "      <td>284</td>\n",
       "      <td>1233</td>\n",
       "      <td>4301</td>\n",
       "      <td>0.102638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155562</th>\n",
       "      <td>torrential</td>\n",
       "      <td>downpours</td>\n",
       "      <td>torrential downpours</td>\n",
       "      <td>10</td>\n",
       "      <td>146</td>\n",
       "      <td>49</td>\n",
       "      <td>0.102564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486223</th>\n",
       "      <td>capacitive</td>\n",
       "      <td>coupling</td>\n",
       "      <td>capacitive coupling</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>66</td>\n",
       "      <td>0.102564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763029</th>\n",
       "      <td>renal</td>\n",
       "      <td>denervation</td>\n",
       "      <td>renal denervation</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>0.102564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765145</th>\n",
       "      <td>mili</td>\n",
       "      <td>tary</td>\n",
       "      <td>mili tary</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0.102564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957290</th>\n",
       "      <td>colpiti</td>\n",
       "      <td>dal</td>\n",
       "      <td>colpiti dal</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.102564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957291</th>\n",
       "      <td>dal</td>\n",
       "      <td>sisma</td>\n",
       "      <td>dal sisma</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>0.102564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>hate</td>\n",
       "      <td>crimes</td>\n",
       "      <td>hate crimes</td>\n",
       "      <td>906</td>\n",
       "      <td>9485</td>\n",
       "      <td>8190</td>\n",
       "      <td>0.102518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>antitrust</td>\n",
       "      <td>approval</td>\n",
       "      <td>antitrust approval</td>\n",
       "      <td>415</td>\n",
       "      <td>1699</td>\n",
       "      <td>6420</td>\n",
       "      <td>0.102229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12098</th>\n",
       "      <td>lone</td>\n",
       "      <td>wolves</td>\n",
       "      <td>lone wolves</td>\n",
       "      <td>99</td>\n",
       "      <td>1493</td>\n",
       "      <td>447</td>\n",
       "      <td>0.102062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308085</th>\n",
       "      <td>spiny</td>\n",
       "      <td>lobsters</td>\n",
       "      <td>spiny lobsters</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>71</td>\n",
       "      <td>0.102041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609781</th>\n",
       "      <td>volu</td>\n",
       "      <td>tion</td>\n",
       "      <td>volu tion</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>0.101695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665585</th>\n",
       "      <td>loveliest</td>\n",
       "      <td>vignette</td>\n",
       "      <td>loveliest vignette</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>44</td>\n",
       "      <td>0.101695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13683</th>\n",
       "      <td>feedback</td>\n",
       "      <td>loop</td>\n",
       "      <td>feedback loop</td>\n",
       "      <td>89</td>\n",
       "      <td>1135</td>\n",
       "      <td>617</td>\n",
       "      <td>0.101598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  w_one          w_two                    phrases  \\\n",
       "172474             karē          raisu                 karē raisu   \n",
       "334844        hemolytic         uremic           hemolytic uremic   \n",
       "374190          llanura        aluvial            llanura aluvial   \n",
       "375243            rumah         gadang               rumah gadang   \n",
       "382393          prolate       spheroid           prolate spheroid   \n",
       "383149         barbeled   dragonfishes      barbeled dragonfishes   \n",
       "396152       latissimus          dorsi           latissimus dorsi   \n",
       "479748             maar         gewoon                maar gewoon   \n",
       "498110  polychlorinated      biphenyls  polychlorinated biphenyls   \n",
       "576352          truncus     arteriosus         truncus arteriosus   \n",
       "613783       substantia          nigra           substantia nigra   \n",
       "620882            panim      chadashot            panim chadashot   \n",
       "682121      polymyalgia     rheumatica     polymyalgia rheumatica   \n",
       "728106             avda     tikvateinu            avda tikvateinu   \n",
       "738746            dolus     eventualis           dolus eventualis   \n",
       "766596       ankylosing    spondylitis     ankylosing spondylitis   \n",
       "807631            unius          libri                unius libri   \n",
       "836873            duces          tecum                duces tecum   \n",
       "850287           schwer      getroffen           schwer getroffen   \n",
       "873504           cursus        honorum             cursus honorum   \n",
       "876797            huwag        tularan              huwag tularan   \n",
       "889527            wishy          washy                wishy washy   \n",
       "932236            creas          ingly                creas ingly   \n",
       "950841             avrà          lunga                 avrà lunga   \n",
       "950842            lunga       gestione             lunga gestione   \n",
       "951093      garantiremo  ricostruzione  garantiremo ricostruzione   \n",
       "957289            paesi        colpiti              paesi colpiti   \n",
       "971550        flagrante        delicto          flagrante delicto   \n",
       "975884          cheggar         yellum             cheggar yellum   \n",
       "981270         damnatio       memoriae          damnatio memoriae   \n",
       "...                 ...            ...                        ...   \n",
       "265740          whoopee       cushions           whoopee cushions   \n",
       "303780            jeune          homme                jeune homme   \n",
       "6623              fried        chicken              fried chicken   \n",
       "5554              ratio        favored              ratio favored   \n",
       "389776          javelin       throwers           javelin throwers   \n",
       "17934          operator    permissions       operator permissions   \n",
       "288673         anorexia        nervosa           anorexia nervosa   \n",
       "6022         nominating       contests        nominating contests   \n",
       "53198          itemized     deductions        itemized deductions   \n",
       "68932          doctoral   dissertation      doctoral dissertation   \n",
       "18014              slam           dunk                  slam dunk   \n",
       "1209            initial         pledge             initial pledge   \n",
       "9061         internally      displaced       internally displaced   \n",
       "40832             razor          blade                razor blade   \n",
       "109957            nitty         gritty               nitty gritty   \n",
       "4209           currency   manipulation      currency manipulation   \n",
       "3140               oral      arguments             oral arguments   \n",
       "155562       torrential      downpours       torrential downpours   \n",
       "486223       capacitive       coupling        capacitive coupling   \n",
       "763029            renal    denervation          renal denervation   \n",
       "765145             mili           tary                  mili tary   \n",
       "957290          colpiti            dal                colpiti dal   \n",
       "957291              dal          sisma                  dal sisma   \n",
       "529                hate         crimes                hate crimes   \n",
       "1843          antitrust       approval         antitrust approval   \n",
       "12098              lone         wolves                lone wolves   \n",
       "308085            spiny       lobsters             spiny lobsters   \n",
       "609781             volu           tion                  volu tion   \n",
       "665585        loveliest       vignette         loveliest vignette   \n",
       "13683          feedback           loop              feedback loop   \n",
       "\n",
       "        phrase_count  freq_one  freq_two  mean_freq_ratio  \n",
       "172474            10        10        10         1.000000  \n",
       "334844             5         5         5         1.000000  \n",
       "374190             5         5         5         1.000000  \n",
       "375243             5         5         5         1.000000  \n",
       "382393             4         4         4         1.000000  \n",
       "383149             4         4         4         1.000000  \n",
       "396152             4         4         4         1.000000  \n",
       "479748             4         4         4         1.000000  \n",
       "498110             3         3         3         1.000000  \n",
       "576352             3         3         3         1.000000  \n",
       "613783             3         3         3         1.000000  \n",
       "620882             3         3         3         1.000000  \n",
       "682121             3         3         3         1.000000  \n",
       "728106             2         2         2         1.000000  \n",
       "738746             2         2         2         1.000000  \n",
       "766596             2         2         2         1.000000  \n",
       "807631             2         2         2         1.000000  \n",
       "836873             2         2         2         1.000000  \n",
       "850287             2         2         2         1.000000  \n",
       "873504             2         2         2         1.000000  \n",
       "876797             2         2         2         1.000000  \n",
       "889527             2         2         2         1.000000  \n",
       "932236             2         2         2         1.000000  \n",
       "950841             2         2         2         1.000000  \n",
       "950842             2         2         2         1.000000  \n",
       "951093             2         2         2         1.000000  \n",
       "957289             2         2         2         1.000000  \n",
       "971550             2         2         2         1.000000  \n",
       "975884             2         2         2         1.000000  \n",
       "981270             2         2         2         1.000000  \n",
       "...              ...       ...       ...              ...  \n",
       "265740             6        14       101         0.104348  \n",
       "303780             6        34        81         0.104348  \n",
       "6623             159       709      2342         0.104228  \n",
       "5554             183      1305      2211         0.104096  \n",
       "389776             4        51        26         0.103896  \n",
       "17934             72      1248       140         0.103746  \n",
       "288673             6       109         7         0.103448  \n",
       "6022             172      1470      1856         0.103428  \n",
       "53198             28        59       483         0.103321  \n",
       "68932             22       256       170         0.103286  \n",
       "18014             71      1169       208         0.103123  \n",
       "1209             547      6582      4045         0.102945  \n",
       "9061             125       712      1720         0.102796  \n",
       "40832             35       269       412         0.102790  \n",
       "109957            15        18       274         0.102740  \n",
       "4209             226      3605       798         0.102657  \n",
       "3140             284      1233      4301         0.102638  \n",
       "155562            10       146        49         0.102564  \n",
       "486223             4        12        66         0.102564  \n",
       "763029             2        36         3         0.102564  \n",
       "765145             2        35         4         0.102564  \n",
       "957290             2         2        37         0.102564  \n",
       "957291             2        37         2         0.102564  \n",
       "529              906      9485      8190         0.102518  \n",
       "1843             415      1699      6420         0.102229  \n",
       "12098             99      1493       447         0.102062  \n",
       "308085             5        27        71         0.102041  \n",
       "609781             3         3        56         0.101695  \n",
       "665585             3        15        44         0.101695  \n",
       "13683             89      1135       617         0.101598  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df.loc[top1000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Part of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lem = WordNetLemmatizer()\n",
    "# lem_words = {}\n",
    "# for x in df.word.values:    \n",
    "#     pos = nltk.pos_tag([x])\n",
    "#     for w,p in pos:\n",
    "#         p_new = get_wordnet_pos(p)\n",
    "#         d = lem.lemmatize(w,p_new)\n",
    "#     lem_words[x] = d    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "#     if treebank_tag.startswith('J'):\n",
    "#         return wordnet.ADJ\n",
    "#     elif treebank_tag.startswith('V'):\n",
    "#         return wordnet.VERB\n",
    "#     elif treebank_tag.startswith('N'):\n",
    "#         return wordnet.NOUN\n",
    "#     elif treebank_tag.startswith('R'):\n",
    "#         return wordnet.ADV\n",
    "#     else:\n",
    "#         return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for w,p in pos:\n",
    "#     p_new = get_wordnet_pos(p)\n",
    "#     lemmed_words.append(lem.lemmatize(w,p_new))\n",
    "#     lemmed_sentence += (w + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w1 = split_df.w_one.replace(lem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2 = split_df.w_two.replace(lem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_df['w1'] = w1\n",
    "# split_df['w2'] = w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have DF with row for every phrase. \n",
    "### Now make one with every word occuring in all phrases\n",
    "### Count how often each word occurs as first, how often it occurs second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_count = Counter(split_df.w_one.values)\n",
    "w2_count = Counter(split_df.w_two.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = w1_count + w2_count\n",
    "words_inc = list(set(word_count.keys()))\n",
    "df = pd.DataFrame(words_inc, columns=['word'])\n",
    "df['start_count'] = df.word.apply(lambda x: w1_count[x])\n",
    "df['end_count'] = df.word.apply(lambda x: w2_count[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22842, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nix_words = ['made', 'make', 'making', 'liking', 'looking', 'like', 'liked', 'likes', \n",
    "             'many', 'even', 'though', 'look', 'looks', 'looked', 'take', 'took', 'know', \n",
    "             'knew', 'knows', 'say', 'said', 'go', 'got', 'much', 'often', 'who', 'whom', \n",
    "             'whose', 'their', 'theirs', 'dozen', 'might', 'may', 'never', 'also', 'still',\n",
    "             'expressed', 'went', 'expresses', 'express', 'expressing', 'saying', 'u']\n",
    "\n",
    "'''\n",
    "when, where, why, that\n",
    "\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.word.isin(nix_words)]\n",
    "split_df = split_df[~split_df.w_two.isin(nix_words)]\n",
    "split_df = split_df[~split_df.w_one.isin(nix_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89479, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_count'] = df.word.apply(lambda x: split_df[split_df.w_one==x]['w_one'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['end_count'] = df.word.apply(lambda x: split_df[split_df.w_two==x]['w_two'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.start_count > 3)&(df.end_count > 3)]\n",
    "# print(df.shape)\n",
    "# df = df[df.end_count > 7]\n",
    "# print(df.shape)\n",
    "# df = df[df.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df = split_df[split_df.w_one.isin(df.word.values)]\n",
    "split_df = split_df[split_df.w_two.isin(df.word.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53133, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv = split_df.loc[:,['phrases', 'w1', 'w2']].sort_values(['w1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv.to_csv('phrase_list.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe remove:\n",
    "made, make, like, many, even, though, first, look, time, (prepositions??) , take, used, using, use, say, know, le, get, much, go, got, often, who, whose, dozen, might, may, never, also, say, seem, still, express, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2197, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['before'] = df.word.apply(lambda x: split_df[split_df.w_two == x].w_one.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['after'] = df.word.apply(lambda x: split_df[split_df.w_one == x].w_two.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69003"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.end_count.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test lem word replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['word_test'] = df.word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.word_test = df.word_test.replace(lem_words)\n",
    "# df.word_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct_dict = df.groupby('word_test').count().word.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['repeats'] = df.word_test.replace(ct_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>start_count</th>\n",
       "      <th>end_count</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>management</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>[team, company, style, firm, system, fee, skil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>normal</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>[life, people, time, person, level, human, rul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>written</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>[statement, testimony, response, question, boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wounded</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>[people, soldier, officer, veteran, man, hundr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>born</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>[citizen, outside, without, classified, female...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  start_count  end_count  \\\n",
       "6   management           24         26   \n",
       "8       normal           43         12   \n",
       "13     written           23         27   \n",
       "14     wounded            9         11   \n",
       "21        born           10         17   \n",
       "\n",
       "                                                after  \n",
       "6   [team, company, style, firm, system, fee, skil...  \n",
       "8   [life, people, time, person, level, human, rul...  \n",
       "13  [statement, testimony, response, question, boo...  \n",
       "14  [people, soldier, officer, veteran, man, hundr...  \n",
       "21  [citizen, outside, without, classified, female...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['all_words'] = df.start_count + df.end_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>start_count</th>\n",
       "      <th>end_count</th>\n",
       "      <th>after</th>\n",
       "      <th>all_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7469</th>\n",
       "      <td>new</td>\n",
       "      <td>901</td>\n",
       "      <td>225</td>\n",
       "      <td>[book, administration, president, study, repor...</td>\n",
       "      <td>1126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>people</td>\n",
       "      <td>528</td>\n",
       "      <td>504</td>\n",
       "      <td>[want, think, around, feel, died, dead, living...</td>\n",
       "      <td>1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8845</th>\n",
       "      <td>political</td>\n",
       "      <td>590</td>\n",
       "      <td>201</td>\n",
       "      <td>[party, analyst, system, leader, class, news, ...</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>first</td>\n",
       "      <td>638</td>\n",
       "      <td>70</td>\n",
       "      <td>[time, place, reported, step, half, round, thi...</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>another</td>\n",
       "      <td>441</td>\n",
       "      <td>153</td>\n",
       "      <td>[way, person, example, man, country, woman, re...</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>last</td>\n",
       "      <td>174</td>\n",
       "      <td>405</td>\n",
       "      <td>[night, time, summer, season, fall, weekend, d...</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>without</td>\n",
       "      <td>276</td>\n",
       "      <td>300</td>\n",
       "      <td>[fear, ever, evidence, knowing, charge, gettin...</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8929</th>\n",
       "      <td>state</td>\n",
       "      <td>285</td>\n",
       "      <td>234</td>\n",
       "      <td>[law, government, medium, official, attorney, ...</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>around</td>\n",
       "      <td>46</td>\n",
       "      <td>469</td>\n",
       "      <td>[town, since, campus, half, people, long, time...</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12110</th>\n",
       "      <td>since</td>\n",
       "      <td>80</td>\n",
       "      <td>410</td>\n",
       "      <td>[last, taking, early, become, leaving, late, b...</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>get</td>\n",
       "      <td>346</td>\n",
       "      <td>131</td>\n",
       "      <td>[back, away, better, involved, along, people, ...</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>government</td>\n",
       "      <td>328</td>\n",
       "      <td>144</td>\n",
       "      <td>[official, agency, force, employee, spending, ...</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3920</th>\n",
       "      <td>public</td>\n",
       "      <td>326</td>\n",
       "      <td>136</td>\n",
       "      <td>[school, health, safety, service, policy, opin...</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>woman</td>\n",
       "      <td>209</td>\n",
       "      <td>245</td>\n",
       "      <td>[named, without, president, voter, wearing, ar...</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467</th>\n",
       "      <td>back</td>\n",
       "      <td>92</td>\n",
       "      <td>360</td>\n",
       "      <td>[home, seat, together, away, control, door, te...</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10601</th>\n",
       "      <td>every</td>\n",
       "      <td>304</td>\n",
       "      <td>146</td>\n",
       "      <td>[single, time, night, state, person, bit, turn...</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249</th>\n",
       "      <td>campaign</td>\n",
       "      <td>251</td>\n",
       "      <td>165</td>\n",
       "      <td>[rally, event, finance, official, stop, rhetor...</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7254</th>\n",
       "      <td>company</td>\n",
       "      <td>188</td>\n",
       "      <td>225</td>\n",
       "      <td>[called, announced, based, behind, executive, ...</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11946</th>\n",
       "      <td>time</td>\n",
       "      <td>170</td>\n",
       "      <td>236</td>\n",
       "      <td>[since, around, period, last, spent, soon, eve...</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9680</th>\n",
       "      <td>group</td>\n",
       "      <td>165</td>\n",
       "      <td>237</td>\n",
       "      <td>[called, known, based, including, claimed, sup...</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10360</th>\n",
       "      <td>right</td>\n",
       "      <td>167</td>\n",
       "      <td>228</td>\n",
       "      <td>[thing, group, away, activist, movement, way, ...</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>policy</td>\n",
       "      <td>183</td>\n",
       "      <td>210</td>\n",
       "      <td>[adviser, change, issue, toward, position, pro...</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9773</th>\n",
       "      <td>official</td>\n",
       "      <td>268</td>\n",
       "      <td>122</td>\n",
       "      <td>[confirmed, believe, statement, state, governm...</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11143</th>\n",
       "      <td>really</td>\n",
       "      <td>329</td>\n",
       "      <td>53</td>\n",
       "      <td>[good, want, hard, need, important, think, bad...</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>good</td>\n",
       "      <td>292</td>\n",
       "      <td>90</td>\n",
       "      <td>[news, thing, job, reason, idea, enough, time,...</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>among</td>\n",
       "      <td>121</td>\n",
       "      <td>254</td>\n",
       "      <td>[others, white, voter, woman, black, people, y...</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>le</td>\n",
       "      <td>235</td>\n",
       "      <td>121</td>\n",
       "      <td>[likely, money, safe, expensive, time, importa...</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6018</th>\n",
       "      <td>police</td>\n",
       "      <td>214</td>\n",
       "      <td>126</td>\n",
       "      <td>[officer, department, chief, shooting, force, ...</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11452</th>\n",
       "      <td>great</td>\n",
       "      <td>296</td>\n",
       "      <td>40</td>\n",
       "      <td>[story, deal, thing, job, people, country, nat...</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>several</td>\n",
       "      <td>232</td>\n",
       "      <td>102</td>\n",
       "      <td>[time, hundred, hour, people, decade, state, r...</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>earn</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>[money, le, enough, back]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6856</th>\n",
       "      <td>deny</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>[service, entry, coverage, whether, people]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11549</th>\n",
       "      <td>resigned</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>[last, amid, rather, following, earlier]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10993</th>\n",
       "      <td>compromise</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>[kept, bill, candidate, national, measure]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>chocolate</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>[chip, bar, factory]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>mail</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>[message, fraud, truck]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>startup</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>[called, company, world]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9758</th>\n",
       "      <td>ranking</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>[member, system, point, official]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4470</th>\n",
       "      <td>subpoena</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[power, issued, related]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>creates</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[new, job, regarding, problem]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>exhibition</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[game, space, hall, season]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9433</th>\n",
       "      <td>passport</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[control, photo, application]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3074</th>\n",
       "      <td>picking</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[fight, side]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11321</th>\n",
       "      <td>panic</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[attack, among]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11936</th>\n",
       "      <td>jumped</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[onto, back, ship]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8701</th>\n",
       "      <td>comeback</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[victory, story, win]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8710</th>\n",
       "      <td>knee</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[injury, replacement, pain]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8744</th>\n",
       "      <td>slip</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[away, back, dress, past]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7201</th>\n",
       "      <td>parliament</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[building, voted, member, passed]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>rely</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[heavily, upon, solely, le]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>edited</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[video]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11923</th>\n",
       "      <td>scholarship</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[program, fund, money, offer]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7753</th>\n",
       "      <td>downtown</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[area, street, hotel, office]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6950</th>\n",
       "      <td>asks</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[whether, people, voter, question]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6932</th>\n",
       "      <td>riot</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[police, broke]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9032</th>\n",
       "      <td>log</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[show, back, onto]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116</th>\n",
       "      <td>cream</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[shop, truck]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>heavyweight</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[title, championship]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6855</th>\n",
       "      <td>disclose</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[meeting, information, payment, detail]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7288</th>\n",
       "      <td>library</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[card, book, director, system]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2197 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  start_count  end_count  \\\n",
       "7469           new          901        225   \n",
       "1874        people          528        504   \n",
       "8845     political          590        201   \n",
       "372          first          638         70   \n",
       "4815       another          441        153   \n",
       "120           last          174        405   \n",
       "1129       without          276        300   \n",
       "8929         state          285        234   \n",
       "842         around           46        469   \n",
       "12110        since           80        410   \n",
       "936            get          346        131   \n",
       "1555    government          328        144   \n",
       "3920        public          326        136   \n",
       "5947         woman          209        245   \n",
       "6467          back           92        360   \n",
       "10601        every          304        146   \n",
       "6249      campaign          251        165   \n",
       "7254       company          188        225   \n",
       "11946         time          170        236   \n",
       "9680         group          165        237   \n",
       "10360        right          167        228   \n",
       "1782        policy          183        210   \n",
       "9773      official          268        122   \n",
       "11143       really          329         53   \n",
       "2425          good          292         90   \n",
       "4901         among          121        254   \n",
       "1295            le          235        121   \n",
       "6018        police          214        126   \n",
       "11452        great          296         40   \n",
       "3485       several          232        102   \n",
       "...            ...          ...        ...   \n",
       "4867          earn            5          4   \n",
       "6856          deny            5          4   \n",
       "11549     resigned            5          4   \n",
       "10993   compromise            5          4   \n",
       "3850     chocolate            5          4   \n",
       "1614          mail            4          5   \n",
       "2852       startup            4          5   \n",
       "9758       ranking            4          5   \n",
       "4470      subpoena            4          4   \n",
       "5109       creates            4          4   \n",
       "3473    exhibition            4          4   \n",
       "9433      passport            4          4   \n",
       "3074       picking            4          4   \n",
       "11321        panic            4          4   \n",
       "11936       jumped            4          4   \n",
       "8701      comeback            4          4   \n",
       "8710          knee            4          4   \n",
       "8744          slip            4          4   \n",
       "7201    parliament            4          4   \n",
       "2610          rely            4          4   \n",
       "2156        edited            4          4   \n",
       "11923  scholarship            4          4   \n",
       "7753      downtown            4          4   \n",
       "6950          asks            4          4   \n",
       "6932          riot            4          4   \n",
       "9032           log            4          4   \n",
       "3116         cream            4          4   \n",
       "4079   heavyweight            4          4   \n",
       "6855      disclose            4          4   \n",
       "7288       library            4          4   \n",
       "\n",
       "                                                   after  all_words  \n",
       "7469   [book, administration, president, study, repor...       1126  \n",
       "1874   [want, think, around, feel, died, dead, living...       1032  \n",
       "8845   [party, analyst, system, leader, class, news, ...        791  \n",
       "372    [time, place, reported, step, half, round, thi...        708  \n",
       "4815   [way, person, example, man, country, woman, re...        594  \n",
       "120    [night, time, summer, season, fall, weekend, d...        579  \n",
       "1129   [fear, ever, evidence, knowing, charge, gettin...        576  \n",
       "8929   [law, government, medium, official, attorney, ...        519  \n",
       "842    [town, since, campus, half, people, long, time...        515  \n",
       "12110  [last, taking, early, become, leaving, late, b...        490  \n",
       "936    [back, away, better, involved, along, people, ...        477  \n",
       "1555   [official, agency, force, employee, spending, ...        472  \n",
       "3920   [school, health, safety, service, policy, opin...        462  \n",
       "5947   [named, without, president, voter, wearing, ar...        454  \n",
       "6467   [home, seat, together, away, control, door, te...        452  \n",
       "10601  [single, time, night, state, person, bit, turn...        450  \n",
       "6249   [rally, event, finance, official, stop, rhetor...        416  \n",
       "7254   [called, announced, based, behind, executive, ...        413  \n",
       "11946  [since, around, period, last, spent, soon, eve...        406  \n",
       "9680   [called, known, based, including, claimed, sup...        402  \n",
       "10360  [thing, group, away, activist, movement, way, ...        395  \n",
       "1782   [adviser, change, issue, toward, position, pro...        393  \n",
       "9773   [confirmed, believe, statement, state, governm...        390  \n",
       "11143  [good, want, hard, need, important, think, bad...        382  \n",
       "2425   [news, thing, job, reason, idea, enough, time,...        382  \n",
       "4901   [others, white, voter, woman, black, people, y...        375  \n",
       "1295   [likely, money, safe, expensive, time, importa...        356  \n",
       "6018   [officer, department, chief, shooting, force, ...        340  \n",
       "11452  [story, deal, thing, job, people, country, nat...        336  \n",
       "3485   [time, hundred, hour, people, decade, state, r...        334  \n",
       "...                                                  ...        ...  \n",
       "4867                           [money, le, enough, back]          9  \n",
       "6856         [service, entry, coverage, whether, people]          9  \n",
       "11549           [last, amid, rather, following, earlier]          9  \n",
       "10993         [kept, bill, candidate, national, measure]          9  \n",
       "3850                                [chip, bar, factory]          9  \n",
       "1614                             [message, fraud, truck]          9  \n",
       "2852                            [called, company, world]          9  \n",
       "9758                   [member, system, point, official]          9  \n",
       "4470                            [power, issued, related]          8  \n",
       "5109                      [new, job, regarding, problem]          8  \n",
       "3473                         [game, space, hall, season]          8  \n",
       "9433                       [control, photo, application]          8  \n",
       "3074                                       [fight, side]          8  \n",
       "11321                                    [attack, among]          8  \n",
       "11936                                 [onto, back, ship]          8  \n",
       "8701                               [victory, story, win]          8  \n",
       "8710                         [injury, replacement, pain]          8  \n",
       "8744                           [away, back, dress, past]          8  \n",
       "7201                   [building, voted, member, passed]          8  \n",
       "2610                         [heavily, upon, solely, le]          8  \n",
       "2156                                             [video]          8  \n",
       "11923                      [program, fund, money, offer]          8  \n",
       "7753                       [area, street, hotel, office]          8  \n",
       "6950                  [whether, people, voter, question]          8  \n",
       "6932                                     [police, broke]          8  \n",
       "9032                                  [show, back, onto]          8  \n",
       "3116                                       [shop, truck]          8  \n",
       "4079                               [title, championship]          8  \n",
       "6855             [meeting, information, payment, detail]          8  \n",
       "7288                      [card, book, director, system]          8  \n",
       "\n",
       "[2197 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['all_words'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Examples of why this lemma doesn't work -- adopted home --> adopt home ; disappointing result --> disappoint result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### don't think this adds anything new, same as other column...\n",
    "\n",
    "#df['num_after'] = df.after.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_count</th>\n",
       "      <th>end_count</th>\n",
       "      <th>after</th>\n",
       "      <th>all_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>management</th>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>[team, company, style, firm, system, fee, skil...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>[life, people, time, person, level, human, rul...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>written</th>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>[statement, testimony, response, question, boo...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wounded</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>[people, soldier, officer, veteran, man, hundr...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>born</th>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>[citizen, outside, without, classified, female...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star</th>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>[power, player, turn, system, witness, turned,...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>provides</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>[free, service, expert, additional, support, a...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global</th>\n",
       "      <td>162</td>\n",
       "      <td>25</td>\n",
       "      <td>[economy, market, financial, temperature, trad...</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>89</td>\n",
       "      <td>185</td>\n",
       "      <td>[among, group, behind, system, staff, network,...</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bar</th>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>[citizen, owner, entry, people, elected, fight...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mile</th>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>[away, per, north, south, east, west, outside,...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daily</th>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>[life, briefing, press, newspaper, routine, in...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disabled</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>[list, people, reporter, child, veteran, perso...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>martial</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>[art, law, artist, beat]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>legally</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>[required, allowed, responsible, changed, poss...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gave</th>\n",
       "      <td>26</td>\n",
       "      <td>38</td>\n",
       "      <td>[birth, way, rise, away, money, speech, people...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single</th>\n",
       "      <td>114</td>\n",
       "      <td>17</td>\n",
       "      <td>[mother, market, person, woman, parent, word, ...</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>militia</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>[group, member, leader, fighter, fighting, for...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employer</th>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>[plan, coverage, added, must, pay]</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>due</th>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>[process, back, date, course, time, next, late...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            start_count  end_count  \\\n",
       "word                                 \n",
       "management           24         26   \n",
       "normal               43         12   \n",
       "written              23         27   \n",
       "wounded               9         11   \n",
       "born                 10         17   \n",
       "star                 24         58   \n",
       "provides             18          8   \n",
       "global              162         25   \n",
       "support              89        185   \n",
       "bar                  18         38   \n",
       "mile                 22         11   \n",
       "daily                40          8   \n",
       "disabled             10          5   \n",
       "martial               4          5   \n",
       "legally              30          4   \n",
       "gave                 26         38   \n",
       "single              114         17   \n",
       "militia               8          6   \n",
       "employer              7         18   \n",
       "due                  10         41   \n",
       "\n",
       "                                                        after  all_words  \n",
       "word                                                                      \n",
       "management  [team, company, style, firm, system, fee, skil...         50  \n",
       "normal      [life, people, time, person, level, human, rul...         55  \n",
       "written     [statement, testimony, response, question, boo...         50  \n",
       "wounded     [people, soldier, officer, veteran, man, hundr...         20  \n",
       "born        [citizen, outside, without, classified, female...         27  \n",
       "star        [power, player, turn, system, witness, turned,...         82  \n",
       "provides    [free, service, expert, additional, support, a...         26  \n",
       "global      [economy, market, financial, temperature, trad...        187  \n",
       "support     [among, group, behind, system, staff, network,...        274  \n",
       "bar         [citizen, owner, entry, people, elected, fight...         56  \n",
       "mile        [away, per, north, south, east, west, outside,...         33  \n",
       "daily       [life, briefing, press, newspaper, routine, in...         48  \n",
       "disabled    [list, people, reporter, child, veteran, perso...         15  \n",
       "martial                              [art, law, artist, beat]          9  \n",
       "legally     [required, allowed, responsible, changed, poss...         34  \n",
       "gave        [birth, way, rise, away, money, speech, people...         64  \n",
       "single      [mother, market, person, woman, parent, word, ...        131  \n",
       "militia     [group, member, leader, fighter, fighting, for...         14  \n",
       "employer                   [plan, coverage, added, must, pay]         25  \n",
       "due         [process, back, date, course, time, next, late...         51  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df.set_index(df.word).drop('word', axis=1)\n",
    "new_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head(50).to_csv('top50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2_filt = { x: count for x, count in w2_count.items() if w2_count[x] >= 10 }\n",
    "# w1_filt = { x: count for x, count in w1_count.items() if w1_count[x] >= 10 }\n",
    "# print(len(w2_filt))\n",
    "# print(len(w1_filt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame([df.word, df.after]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df.set_index(temp_df.word).drop('word', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict0 = temp_df.T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {k:v[0].tolist() for k, v in word_dict0.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temp_dict.pickle', 'wb') as outputfile:\n",
    "    pickle.dump(word_dict, outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pick key randomly\n",
    "word_list = []\n",
    "word1 = random.choice(list(word_dict.keys()))\n",
    "word_list.append(word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_new(l_word, word_list):\n",
    "    rng = list(range(len(word_dict[l_word])))\n",
    "    random.shuffle(rng)\n",
    "    random.shuffle(rng)\n",
    "    choices = list(np.array(word_dict[l_word])[rng])\n",
    "    for i in range(len(choices)):\n",
    "        l = len(choices)\n",
    "        if l > 0:\n",
    "            if choices[i] in word_dict.keys():\n",
    "                if choices[i] not in word_list:\n",
    "                    new_word = choices[i]\n",
    "                    word_list.append(new_word)\n",
    "                    break\n",
    "                else:\n",
    "                    choices.remove(choices[i])\n",
    "        else:\n",
    "            raise InputError('No choices left')\n",
    "    return new_word, word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Eliminate repeats to avoid :\n",
    "\n",
    "Dogs \n",
    "Walk\n",
    "Dogs\n",
    "Walk\n",
    "...\n",
    "\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_set():\n",
    "    word_list = []\n",
    "    word1 = random.choice(list(word_dict.keys()))\n",
    "    word_list.append(word1)\n",
    "    \n",
    "    word2, word_list = pick_new(word1, word_list)\n",
    "    word3, word_list = pick_new(word2, word_list)\n",
    "    word4, word_list = pick_new(word3, word_list)\n",
    "    word5, word_list = pick_new(word4, word_list)\n",
    "    word6, word_list = pick_new(word5, word_list)\n",
    "    word7, word_list = pick_new(word6, word_list)\n",
    "    word8, word_list = pick_new(word7, word_list)\n",
    "    word9, word_list = pick_new(word8, word_list)\n",
    "    word10, word_list = pick_new(word9, word_list)\n",
    "    return word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = pick_set()\n",
    "list2 = pick_set()\n",
    "list3 = pick_set()\n",
    "list4 = pick_set()\n",
    "list5 = pick_set()\n",
    "list6 = pick_set()\n",
    "list7 = pick_set()\n",
    "list8 = pick_set()\n",
    "list9 = pick_set()\n",
    "list10 = pick_set()\n",
    "list11 = pick_set()\n",
    "list12 = pick_set()\n",
    "list13 = pick_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'statement', 'later', 'allowed', 'people', 'fought', 'hard', 'thing', 'become', 'president']\n",
      "['terrorist', 'crime', 'rose', 'gold', 'standard', 'regarding', 'immigration', 'enforcement', 'activity', 'outside']\n",
      "['eating', 'dinner', 'party', 'already', 'talking', 'politics', 'right', 'man', 'started', 'training']\n",
      "['simply', 'call', 'ended', 'without', 'trying', 'new', 'history', 'department', 'need', 'today']\n",
      "['comment', 'came', 'away', 'money', 'talk', 'begin', 'work', 'closely', 'followed', 'suit']\n",
      "['seem', 'increasingly', 'turned', 'head', 'next', 'meet', 'weekly', 'column', 'called', 'cop']\n",
      "['positive', 'note', 'taken', 'inside', 'story', 'straight', 'man', 'fell', 'sharply', 'cut']\n",
      "['bankruptcy', 'last', 'winter', 'blue', 'blood', 'test', 'run', 'without', 'anything', 'unusual']\n",
      "['household', 'item', 'including', 'cutting', 'deal', 'since', 'news', 'agenda', 'without', 'receiving']\n",
      "['shot', 'behind', 'bar', 'elected', 'lawmaker', 'last', 'good', 'effect', 'immediately', 'attracted']\n",
      "['scholarship', 'fund', 'abortion', 'per', 'season', 'began', 'coming', 'together', 'every', 'female']\n",
      "['educated', 'person', 'per', 'user', 'experience', 'via', 'trade', 'data', 'regarding', 'illegal']\n",
      "['half', 'time', 'machine', 'gun', 'via', 'social', 'network', 'security', 'crisis', 'point']\n"
     ]
    }
   ],
   "source": [
    "print(list1)\n",
    "print(list2)\n",
    "print(list3)\n",
    "print(list4)\n",
    "print(list5)\n",
    "print(list6)\n",
    "print(list7)\n",
    "print(list8)\n",
    "print(list9)\n",
    "print(list10)\n",
    "print(list11)\n",
    "print(list12)\n",
    "print(list13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'released'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2, word_list = pick_new(word1, word_list)\n",
    "word2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'immediately'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word3, word_list = pick_new(word2, word_list)\n",
    "word3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'upon'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word4, word_list = pick_new(word3, word_list)\n",
    "word4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'release'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word5, word_list = pick_new(word4, word_list)\n",
    "word5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'video'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word6, word_list = pick_new(word5, word_list)\n",
    "word6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'game'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word7, word_list = pick_new(word6, word_list)\n",
    "word7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'behind'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word8, word_list = pick_new(word7, word_list)\n",
    "word8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wall'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word9, word_list = pick_new(word8, word_list)\n",
    "word9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'around'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word10, word_list = pick_new(word9, word_list)\n",
    "word10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
